{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.1"},"colab":{"name":"2_OpenAPI_yfinance_tensorflow_lstm_stockprice.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"U8pJ72QbV1-B"},"source":["https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras"]},{"cell_type":"markdown","metadata":{"id":"tD5UbWogSXTH"},"source":["# 1. Packages"]},{"cell_type":"code","metadata":{"id":"e-FR7yD0IAVZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623555397649,"user_tz":-540,"elapsed":5892,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}},"outputId":"820e24fb-891b-457f-f9fe-c8b5f7514b65"},"source":["!pip install yfinance # yahoo_fin"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting yfinance\n","  Downloading https://files.pythonhosted.org/packages/a7/ee/315752b9ef281ba83c62aa7ec2e2074f85223da6e7e74efb4d3e11c0f510/yfinance-0.1.59.tar.gz\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n","Collecting lxml>=4.5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/c0/d0526314971fc661b083ab135747dc68446a3022686da8c16d25fcf6ef07/lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3MB)\n","\u001b[K     |████████████████████████████████| 6.3MB 12.8MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n","Building wheels for collected packages: yfinance\n","  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for yfinance: filename=yfinance-0.1.59-py2.py3-none-any.whl size=23455 sha256=7985f586e81b1144ee07c3ca7c72adea14299e723b39d71536e4c523f08cca61\n","  Stored in directory: /root/.cache/pip/wheels/f8/2a/0f/4b5a86e1d52e451757eb6bc17fd899629f0925c777741b6d04\n","Successfully built yfinance\n","Installing collected packages: lxml, yfinance\n","  Found existing installation: lxml 4.2.6\n","    Uninstalling lxml-4.2.6:\n","      Successfully uninstalled lxml-4.2.6\n","Successfully installed lxml-4.6.3 yfinance-0.1.59\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N45M19d5FrK3"},"source":["The dataset used in this notebook is Tesla stock history from 2014 to 2017. You can find the .csv file in the project folder."]},{"cell_type":"markdown","metadata":{"id":"LlNv7xrhSd0Z"},"source":["# 2. LIbraries"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"VxDlPMbeFrK5","executionInfo":{"status":"ok","timestamp":1623555400006,"user_tz":-540,"elapsed":2359,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import random\n","import pandas_datareader as pdr\n","import tensorflow as tf\n","import yfinance as yf\n","\n","from datetime import datetime\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","# from yahoo_fin import stock_info as si\n","from collections import deque"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OrDEzHBZFrK8"},"source":["# 3. Data preprocessing "]},{"cell_type":"code","metadata":{"id":"GEKv894lOfJT","executionInfo":{"status":"ok","timestamp":1623555400009,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# set seed, so we can get the same results after rerunning several times\n","np.random.seed(314)\n","tf.random.set_seed(314)\n","random.seed(314)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"GPrZNwYPOjXr","executionInfo":{"status":"ok","timestamp":1623555400010,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["def shuffle_in_unison(a, b):\n","    # shuffle two arrays in the same way\n","    state = np.random.get_state()\n","    np.random.shuffle(a)\n","    np.random.set_state(state)\n","    np.random.shuffle(b)\n","\n","def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n","                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n","    \"\"\"\n","    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n","    Params:\n","        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n","        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n","        scale (bool): whether to scale prices from 0 to 1, default is True\n","        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n","        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n","        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n","            to False will split datasets in a random way\n","        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n","        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n","    \"\"\"\n","    # see if ticker is already a loaded stock from yahoo finance\n","    if isinstance(ticker, str):\n","        # load it from yahoo_fin library\n","        # df = si.get_data(ticker)\n","        # df = si.get_data(ticker, start_date = \"09/01/2020\", end_date = \"06/05/2021\")\n","        # brk = yf.Ticker('TSLA')\n","\n","        df = yf.download(\"NVDA\", start=\"2019-09-01\", end=\"2021-06-30\") #TSLA MSFT NVDA\n","        df = df.rename(columns={'Open': 'open','High': 'high','Low': 'low','Adj Close': 'adjclose','Volume': 'volume'})\n","        df = df[[\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]]\n","\n","    elif isinstance(ticker, pd.DataFrame):\n","        # already loaded, use it directly\n","        df = ticker\n","    else:\n","        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n","    # this will contain all the elements we want to return from this function\n","    result = {}\n","    # we will also return the original dataframe itself\n","    result['df'] = df.copy()\n","    # make sure that the passed feature_columns exist in the dataframe\n","    for col in feature_columns:\n","        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n","    # add date as a column\n","    if \"date\" not in df.columns:\n","        df[\"date\"] = df.index\n","    if scale:\n","        column_scaler = {}\n","        # scale the data (prices) from 0 to 1\n","        for column in feature_columns:\n","            scaler = preprocessing.MinMaxScaler()\n","            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n","            column_scaler[column] = scaler\n","        # add the MinMaxScaler instances to the result returned\n","        result[\"column_scaler\"] = column_scaler\n","    # add the target column (label) by shifting by `lookup_step`\n","    df['future'] = df['adjclose'].shift(-lookup_step)\n","    # last `lookup_step` columns contains NaN in future column\n","    # get them before droping NaNs\n","    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n","    # drop NaNs\n","    df.dropna(inplace=True)\n","    sequence_data = []\n","    sequences = deque(maxlen=n_steps)\n","    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n","        sequences.append(entry)\n","        if len(sequences) == n_steps:\n","            sequence_data.append([np.array(sequences), target])\n","    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n","    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n","    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n","    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n","    last_sequence = np.array(last_sequence).astype(np.float32)\n","    # add to result\n","    result['last_sequence'] = last_sequence\n","    # construct the X's and y's\n","    X, y = [], []\n","    for seq, target in sequence_data:\n","        X.append(seq)\n","        y.append(target)\n","    # convert to numpy arrays\n","    X = np.array(X)\n","    y = np.array(y)\n","    if split_by_date:\n","        # split the dataset into training & testing sets by date (not randomly splitting)\n","        train_samples = int((1 - test_size) * len(X))\n","        result[\"X_train\"] = X[:train_samples]\n","        result[\"y_train\"] = y[:train_samples]\n","        result[\"X_test\"]  = X[train_samples:]\n","        result[\"y_test\"]  = y[train_samples:]\n","        if shuffle:\n","            # shuffle the datasets for training (if shuffle parameter is set)\n","            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n","            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n","    else:    \n","        # split the dataset randomly\n","        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n","                                                                                test_size=test_size, shuffle=shuffle)\n","    # get the list of test set dates\n","    dates = result[\"X_test\"][:, -1, -1]\n","    # retrieve test features from the original dataframe\n","    result[\"test_df\"] = result[\"df\"].loc[dates]\n","    # remove duplicated dates in the testing dataframe\n","    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n","    # remove dates from the training/testing sets & convert to float32\n","    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n","    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n","    return result"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_1w31EmXFrK_"},"source":["# 4. Modeling"]},{"cell_type":"markdown","metadata":{"id":"1vnlEgvSFrLA"},"source":["In this notebook I am implementing LSTM cell from scratch using TensorFlow. In the next 2 cells you will find weights and implementation of the LSTM cell."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"WoRlodiRFrLA","executionInfo":{"status":"ok","timestamp":1623555400010,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n","                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n","    model = Sequential()\n","    for i in range(n_layers):\n","        if i == 0:\n","            # first layer\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n","            else:\n","                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n","        elif i == n_layers - 1:\n","            # last layer\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=False)))\n","            else:\n","                model.add(cell(units, return_sequences=False))\n","        else:\n","            # hidden layers\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=True)))\n","            else:\n","                model.add(cell(units, return_sequences=True))\n","        # add dropout after each layer\n","        model.add(Dropout(dropout))\n","    model.add(Dense(1, activation=\"linear\"))\n","    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n","    return model"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IDrLKQriFrLB"},"source":["This is definition of LSTM cell. The best explanation of the LSTM you will find [here](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)"]},{"cell_type":"markdown","metadata":{"id":"lrO6SEWuTXQl"},"source":["# 5. Training"]},{"cell_type":"markdown","metadata":{"id":"8UWtEWnaFrLE"},"source":["### Time to train the network "]},{"cell_type":"code","metadata":{"id":"ZP-_pMFLFrLF","executionInfo":{"status":"ok","timestamp":1623555400010,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["import os\n","import time\n","from tensorflow.keras.layers import LSTM\n","\n","# Window size or the sequence length\n","N_STEPS = 50\n","# Lookup step, 1 is the next day\n","LOOKUP_STEP = 15\n","# whether to scale feature columns & output price as well\n","SCALE = True\n","scale_str = f\"sc-{int(SCALE)}\"\n","# whether to shuffle the dataset\n","SHUFFLE = True\n","shuffle_str = f\"sh-{int(SHUFFLE)}\"\n","# whether to split the training/testing set by date\n","SPLIT_BY_DATE = False\n","split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n","# test ratio size, 0.2 is 20%\n","TEST_SIZE = 0.2\n","# features to use\n","FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n","# date now\n","date_now = time.strftime(\"%Y-%m-%d\")\n","### model parameters\n","N_LAYERS = 2\n","# LSTM cell\n","CELL = LSTM\n","# 256 LSTM neurons\n","UNITS = 256\n","# 40% dropout\n","DROPOUT = 0.4\n","# whether to use bidirectional RNNs\n","BIDIRECTIONAL = False\n","### training parameters\n","# mean absolute error loss\n","# LOSS = \"mae\"\n","# huber loss\n","LOSS = \"huber_loss\"\n","OPTIMIZER = \"adam\"\n","BATCH_SIZE = 64\n","EPOCHS = 500\n","\n","# Define the instruments to download. We would like to see Apple, Microsoft and the S&P500 index.\n","# tickers = ['TSLA'] #, 'NVDA', '^GSPC']\n","ticker = \"NVDA\" # TSLA MSFT NVDA\n","\n","ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n","# model name to save, making it as unique as possible based on parameters\n","model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n","{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n","if BIDIRECTIONAL:\n","    model_name += \"-b\""],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"rI3fniVePa6p","executionInfo":{"status":"ok","timestamp":1623555400010,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# create these folders if they does not exist\n","if not os.path.isdir(\"results\"):\n","    os.mkdir(\"results\")\n","if not os.path.isdir(\"logs\"):\n","    os.mkdir(\"logs\")\n","if not os.path.isdir(\"data\"):\n","    os.mkdir(\"data\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"JO5DihQGPaBG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623555490857,"user_tz":-540,"elapsed":90853,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}},"outputId":"63d0e904-33ad-4434-a51d-25c94bd0bcb4"},"source":["# load the data\n","data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n","                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n","                feature_columns=FEATURE_COLUMNS)\n","# save the dataframe\n","data[\"df\"].to_csv(ticker_data_filename)\n","# construct the model\n","model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n","                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n","# some tensorflow callbacks\n","checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n","tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n","# train the model and save the weights whenever we see \n","# a new optimal model using ModelCheckpoint\n","history = model.fit(data[\"X_train\"], data[\"y_train\"],\n","                    batch_size=BATCH_SIZE,\n","                    epochs=EPOCHS,\n","                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n","                    callbacks=[checkpointer, tensorboard],\n","                    verbose=1)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\r[*********************100%***********************]  1 of 1 completed\n","Epoch 1/500\n","5/5 [==============================] - 10s 362ms/step - loss: 0.0571 - mean_absolute_error: 0.2422 - val_loss: 0.0241 - val_mean_absolute_error: 0.1912\n","\n","Epoch 00001: val_loss improved from inf to 0.02413, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 2/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0218 - mean_absolute_error: 0.1723 - val_loss: 0.0031 - val_mean_absolute_error: 0.0563\n","\n","Epoch 00002: val_loss improved from 0.02413 to 0.00313, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 3/500\n","5/5 [==============================] - 0s 26ms/step - loss: 0.0077 - mean_absolute_error: 0.0953 - val_loss: 0.0040 - val_mean_absolute_error: 0.0712\n","\n","Epoch 00003: val_loss did not improve from 0.00313\n","Epoch 4/500\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0047 - mean_absolute_error: 0.0740 - val_loss: 0.0054 - val_mean_absolute_error: 0.0816\n","\n","Epoch 00004: val_loss did not improve from 0.00313\n","Epoch 5/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0052 - mean_absolute_error: 0.0751 - val_loss: 0.0028 - val_mean_absolute_error: 0.0580\n","\n","Epoch 00005: val_loss improved from 0.00313 to 0.00283, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 6/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0049 - mean_absolute_error: 0.0752 - val_loss: 0.0033 - val_mean_absolute_error: 0.0635\n","\n","Epoch 00006: val_loss did not improve from 0.00283\n","Epoch 7/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0037 - mean_absolute_error: 0.0636 - val_loss: 0.0033 - val_mean_absolute_error: 0.0593\n","\n","Epoch 00007: val_loss did not improve from 0.00283\n","Epoch 8/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_absolute_error: 0.0723 - val_loss: 0.0027 - val_mean_absolute_error: 0.0560\n","\n","Epoch 00008: val_loss improved from 0.00283 to 0.00269, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 9/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0039 - mean_absolute_error: 0.0655 - val_loss: 0.0028 - val_mean_absolute_error: 0.0581\n","\n","Epoch 00009: val_loss did not improve from 0.00269\n","Epoch 10/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0040 - mean_absolute_error: 0.0671 - val_loss: 0.0029 - val_mean_absolute_error: 0.0553\n","\n","Epoch 00010: val_loss did not improve from 0.00269\n","Epoch 11/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0039 - mean_absolute_error: 0.0654 - val_loss: 0.0027 - val_mean_absolute_error: 0.0562\n","\n","Epoch 00011: val_loss improved from 0.00269 to 0.00268, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 12/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0658 - val_loss: 0.0027 - val_mean_absolute_error: 0.0560\n","\n","Epoch 00012: val_loss improved from 0.00268 to 0.00266, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 13/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0031 - mean_absolute_error: 0.0596 - val_loss: 0.0027 - val_mean_absolute_error: 0.0537\n","\n","Epoch 00013: val_loss did not improve from 0.00266\n","Epoch 14/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0614 - val_loss: 0.0027 - val_mean_absolute_error: 0.0568\n","\n","Epoch 00014: val_loss did not improve from 0.00266\n","Epoch 15/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0033 - mean_absolute_error: 0.0614 - val_loss: 0.0026 - val_mean_absolute_error: 0.0542\n","\n","Epoch 00015: val_loss improved from 0.00266 to 0.00257, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 16/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0644 - val_loss: 0.0026 - val_mean_absolute_error: 0.0536\n","\n","Epoch 00016: val_loss did not improve from 0.00257\n","Epoch 17/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0034 - mean_absolute_error: 0.0603 - val_loss: 0.0027 - val_mean_absolute_error: 0.0575\n","\n","Epoch 00017: val_loss did not improve from 0.00257\n","Epoch 18/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0034 - mean_absolute_error: 0.0613 - val_loss: 0.0026 - val_mean_absolute_error: 0.0533\n","\n","Epoch 00018: val_loss did not improve from 0.00257\n","Epoch 19/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0621 - val_loss: 0.0025 - val_mean_absolute_error: 0.0545\n","\n","Epoch 00019: val_loss improved from 0.00257 to 0.00255, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 20/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0035 - mean_absolute_error: 0.0601 - val_loss: 0.0026 - val_mean_absolute_error: 0.0559\n","\n","Epoch 00020: val_loss did not improve from 0.00255\n","Epoch 21/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0031 - mean_absolute_error: 0.0589 - val_loss: 0.0025 - val_mean_absolute_error: 0.0539\n","\n","Epoch 00021: val_loss improved from 0.00255 to 0.00250, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 22/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0649 - val_loss: 0.0025 - val_mean_absolute_error: 0.0533\n","\n","Epoch 00022: val_loss improved from 0.00250 to 0.00249, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 23/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0602 - val_loss: 0.0026 - val_mean_absolute_error: 0.0570\n","\n","Epoch 00023: val_loss did not improve from 0.00249\n","Epoch 24/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0034 - mean_absolute_error: 0.0633 - val_loss: 0.0025 - val_mean_absolute_error: 0.0526\n","\n","Epoch 00024: val_loss did not improve from 0.00249\n","Epoch 25/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0038 - mean_absolute_error: 0.0657 - val_loss: 0.0025 - val_mean_absolute_error: 0.0523\n","\n","Epoch 00025: val_loss improved from 0.00249 to 0.00248, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 26/500\n","5/5 [==============================] - 0s 16ms/step - loss: 0.0032 - mean_absolute_error: 0.0589 - val_loss: 0.0025 - val_mean_absolute_error: 0.0537\n","\n","Epoch 00026: val_loss improved from 0.00248 to 0.00248, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 27/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0034 - mean_absolute_error: 0.0615 - val_loss: 0.0024 - val_mean_absolute_error: 0.0522\n","\n","Epoch 00027: val_loss improved from 0.00248 to 0.00244, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 28/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0028 - mean_absolute_error: 0.0559 - val_loss: 0.0024 - val_mean_absolute_error: 0.0533\n","\n","Epoch 00028: val_loss did not improve from 0.00244\n","Epoch 29/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0632 - val_loss: 0.0025 - val_mean_absolute_error: 0.0514\n","\n","Epoch 00029: val_loss did not improve from 0.00244\n","Epoch 30/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0031 - mean_absolute_error: 0.0580 - val_loss: 0.0026 - val_mean_absolute_error: 0.0571\n","\n","Epoch 00030: val_loss did not improve from 0.00244\n","Epoch 31/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0033 - mean_absolute_error: 0.0601 - val_loss: 0.0025 - val_mean_absolute_error: 0.0514\n","\n","Epoch 00031: val_loss did not improve from 0.00244\n","Epoch 32/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0573 - val_loss: 0.0024 - val_mean_absolute_error: 0.0530\n","\n","Epoch 00032: val_loss improved from 0.00244 to 0.00237, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 33/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0032 - mean_absolute_error: 0.0586 - val_loss: 0.0023 - val_mean_absolute_error: 0.0522\n","\n","Epoch 00033: val_loss improved from 0.00237 to 0.00233, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 34/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0034 - mean_absolute_error: 0.0595 - val_loss: 0.0023 - val_mean_absolute_error: 0.0519\n","\n","Epoch 00034: val_loss improved from 0.00233 to 0.00233, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 35/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0030 - mean_absolute_error: 0.0581 - val_loss: 0.0023 - val_mean_absolute_error: 0.0510\n","\n","Epoch 00035: val_loss improved from 0.00233 to 0.00232, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 36/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0030 - mean_absolute_error: 0.0567 - val_loss: 0.0024 - val_mean_absolute_error: 0.0539\n","\n","Epoch 00036: val_loss did not improve from 0.00232\n","Epoch 37/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0583 - val_loss: 0.0023 - val_mean_absolute_error: 0.0512\n","\n","Epoch 00037: val_loss improved from 0.00232 to 0.00226, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 38/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0031 - mean_absolute_error: 0.0604 - val_loss: 0.0023 - val_mean_absolute_error: 0.0531\n","\n","Epoch 00038: val_loss did not improve from 0.00226\n","Epoch 39/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0028 - mean_absolute_error: 0.0558 - val_loss: 0.0022 - val_mean_absolute_error: 0.0513\n","\n","Epoch 00039: val_loss improved from 0.00226 to 0.00224, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 40/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0575 - val_loss: 0.0022 - val_mean_absolute_error: 0.0495\n","\n","Epoch 00040: val_loss did not improve from 0.00224\n","Epoch 41/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0587 - val_loss: 0.0022 - val_mean_absolute_error: 0.0514\n","\n","Epoch 00041: val_loss improved from 0.00224 to 0.00222, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 42/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0030 - mean_absolute_error: 0.0571 - val_loss: 0.0023 - val_mean_absolute_error: 0.0529\n","\n","Epoch 00042: val_loss did not improve from 0.00222\n","Epoch 43/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0031 - mean_absolute_error: 0.0598 - val_loss: 0.0022 - val_mean_absolute_error: 0.0484\n","\n","Epoch 00043: val_loss improved from 0.00222 to 0.00220, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 44/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0027 - mean_absolute_error: 0.0544 - val_loss: 0.0022 - val_mean_absolute_error: 0.0508\n","\n","Epoch 00044: val_loss improved from 0.00220 to 0.00217, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 45/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0028 - mean_absolute_error: 0.0541 - val_loss: 0.0021 - val_mean_absolute_error: 0.0505\n","\n","Epoch 00045: val_loss improved from 0.00217 to 0.00213, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 46/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0026 - mean_absolute_error: 0.0540 - val_loss: 0.0021 - val_mean_absolute_error: 0.0494\n","\n","Epoch 00046: val_loss improved from 0.00213 to 0.00210, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 47/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0030 - mean_absolute_error: 0.0569 - val_loss: 0.0023 - val_mean_absolute_error: 0.0538\n","\n","Epoch 00047: val_loss did not improve from 0.00210\n","Epoch 48/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0031 - mean_absolute_error: 0.0570 - val_loss: 0.0021 - val_mean_absolute_error: 0.0507\n","\n","Epoch 00048: val_loss did not improve from 0.00210\n","Epoch 49/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0032 - mean_absolute_error: 0.0604 - val_loss: 0.0029 - val_mean_absolute_error: 0.0547\n","\n","Epoch 00049: val_loss did not improve from 0.00210\n","Epoch 50/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0036 - mean_absolute_error: 0.0627 - val_loss: 0.0028 - val_mean_absolute_error: 0.0608\n","\n","Epoch 00050: val_loss did not improve from 0.00210\n","Epoch 51/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0032 - mean_absolute_error: 0.0598 - val_loss: 0.0021 - val_mean_absolute_error: 0.0485\n","\n","Epoch 00051: val_loss did not improve from 0.00210\n","Epoch 52/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0029 - mean_absolute_error: 0.0579 - val_loss: 0.0021 - val_mean_absolute_error: 0.0489\n","\n","Epoch 00052: val_loss did not improve from 0.00210\n","Epoch 53/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0034 - mean_absolute_error: 0.0607 - val_loss: 0.0025 - val_mean_absolute_error: 0.0576\n","\n","Epoch 00053: val_loss did not improve from 0.00210\n","Epoch 54/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0557 - val_loss: 0.0021 - val_mean_absolute_error: 0.0480\n","\n","Epoch 00054: val_loss improved from 0.00210 to 0.00209, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 55/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0028 - mean_absolute_error: 0.0561 - val_loss: 0.0021 - val_mean_absolute_error: 0.0499\n","\n","Epoch 00055: val_loss improved from 0.00209 to 0.00208, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 56/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0555 - val_loss: 0.0021 - val_mean_absolute_error: 0.0518\n","\n","Epoch 00056: val_loss did not improve from 0.00208\n","Epoch 57/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0030 - mean_absolute_error: 0.0576 - val_loss: 0.0023 - val_mean_absolute_error: 0.0482\n","\n","Epoch 00057: val_loss did not improve from 0.00208\n","Epoch 58/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0030 - mean_absolute_error: 0.0574 - val_loss: 0.0023 - val_mean_absolute_error: 0.0554\n","\n","Epoch 00058: val_loss did not improve from 0.00208\n","Epoch 59/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0521 - val_loss: 0.0021 - val_mean_absolute_error: 0.0471\n","\n","Epoch 00059: val_loss improved from 0.00208 to 0.00206, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 60/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0027 - mean_absolute_error: 0.0553 - val_loss: 0.0020 - val_mean_absolute_error: 0.0501\n","\n","Epoch 00060: val_loss improved from 0.00206 to 0.00205, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 61/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0483 - val_loss: 0.0021 - val_mean_absolute_error: 0.0519\n","\n","Epoch 00061: val_loss did not improve from 0.00205\n","Epoch 62/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0027 - mean_absolute_error: 0.0544 - val_loss: 0.0020 - val_mean_absolute_error: 0.0498\n","\n","Epoch 00062: val_loss improved from 0.00205 to 0.00205, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 63/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0027 - mean_absolute_error: 0.0560 - val_loss: 0.0022 - val_mean_absolute_error: 0.0478\n","\n","Epoch 00063: val_loss did not improve from 0.00205\n","Epoch 64/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0031 - mean_absolute_error: 0.0588 - val_loss: 0.0020 - val_mean_absolute_error: 0.0480\n","\n","Epoch 00064: val_loss improved from 0.00205 to 0.00201, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 65/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0031 - mean_absolute_error: 0.0550 - val_loss: 0.0030 - val_mean_absolute_error: 0.0651\n","\n","Epoch 00065: val_loss did not improve from 0.00201\n","Epoch 66/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0037 - mean_absolute_error: 0.0650 - val_loss: 0.0021 - val_mean_absolute_error: 0.0486\n","\n","Epoch 00066: val_loss did not improve from 0.00201\n","Epoch 67/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0025 - mean_absolute_error: 0.0518 - val_loss: 0.0021 - val_mean_absolute_error: 0.0511\n","\n","Epoch 00067: val_loss did not improve from 0.00201\n","Epoch 68/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0028 - mean_absolute_error: 0.0542 - val_loss: 0.0021 - val_mean_absolute_error: 0.0493\n","\n","Epoch 00068: val_loss did not improve from 0.00201\n","Epoch 69/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0028 - mean_absolute_error: 0.0546 - val_loss: 0.0021 - val_mean_absolute_error: 0.0514\n","\n","Epoch 00069: val_loss did not improve from 0.00201\n","Epoch 70/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0027 - mean_absolute_error: 0.0545 - val_loss: 0.0020 - val_mean_absolute_error: 0.0480\n","\n","Epoch 00070: val_loss did not improve from 0.00201\n","Epoch 71/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0026 - mean_absolute_error: 0.0547 - val_loss: 0.0021 - val_mean_absolute_error: 0.0477\n","\n","Epoch 00071: val_loss did not improve from 0.00201\n","Epoch 72/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0030 - mean_absolute_error: 0.0569 - val_loss: 0.0022 - val_mean_absolute_error: 0.0538\n","\n","Epoch 00072: val_loss did not improve from 0.00201\n","Epoch 73/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0034 - mean_absolute_error: 0.0595 - val_loss: 0.0024 - val_mean_absolute_error: 0.0583\n","\n","Epoch 00073: val_loss did not improve from 0.00201\n","Epoch 74/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0026 - mean_absolute_error: 0.0550 - val_loss: 0.0021 - val_mean_absolute_error: 0.0469\n","\n","Epoch 00074: val_loss did not improve from 0.00201\n","Epoch 75/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0027 - mean_absolute_error: 0.0538 - val_loss: 0.0021 - val_mean_absolute_error: 0.0531\n","\n","Epoch 00075: val_loss did not improve from 0.00201\n","Epoch 76/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0516 - val_loss: 0.0021 - val_mean_absolute_error: 0.0467\n","\n","Epoch 00076: val_loss did not improve from 0.00201\n","Epoch 77/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0027 - mean_absolute_error: 0.0525 - val_loss: 0.0023 - val_mean_absolute_error: 0.0555\n","\n","Epoch 00077: val_loss did not improve from 0.00201\n","Epoch 78/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0027 - mean_absolute_error: 0.0556 - val_loss: 0.0020 - val_mean_absolute_error: 0.0506\n","\n","Epoch 00078: val_loss did not improve from 0.00201\n","Epoch 79/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0546 - val_loss: 0.0020 - val_mean_absolute_error: 0.0466\n","\n","Epoch 00079: val_loss improved from 0.00201 to 0.00201, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 80/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0027 - mean_absolute_error: 0.0550 - val_loss: 0.0022 - val_mean_absolute_error: 0.0543\n","\n","Epoch 00080: val_loss did not improve from 0.00201\n","Epoch 81/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0029 - mean_absolute_error: 0.0553 - val_loss: 0.0020 - val_mean_absolute_error: 0.0482\n","\n","Epoch 00081: val_loss improved from 0.00201 to 0.00196, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 82/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0027 - mean_absolute_error: 0.0557 - val_loss: 0.0021 - val_mean_absolute_error: 0.0533\n","\n","Epoch 00082: val_loss did not improve from 0.00196\n","Epoch 83/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0026 - mean_absolute_error: 0.0533 - val_loss: 0.0019 - val_mean_absolute_error: 0.0477\n","\n","Epoch 00083: val_loss improved from 0.00196 to 0.00194, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 84/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0027 - mean_absolute_error: 0.0546 - val_loss: 0.0022 - val_mean_absolute_error: 0.0554\n","\n","Epoch 00084: val_loss did not improve from 0.00194\n","Epoch 85/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0030 - mean_absolute_error: 0.0578 - val_loss: 0.0020 - val_mean_absolute_error: 0.0460\n","\n","Epoch 00085: val_loss did not improve from 0.00194\n","Epoch 86/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0553 - val_loss: 0.0022 - val_mean_absolute_error: 0.0543\n","\n","Epoch 00086: val_loss did not improve from 0.00194\n","Epoch 87/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0029 - mean_absolute_error: 0.0554 - val_loss: 0.0022 - val_mean_absolute_error: 0.0552\n","\n","Epoch 00087: val_loss did not improve from 0.00194\n","Epoch 88/500\n","5/5 [==============================] - 0s 16ms/step - loss: 0.0028 - mean_absolute_error: 0.0545 - val_loss: 0.0020 - val_mean_absolute_error: 0.0464\n","\n","Epoch 00088: val_loss did not improve from 0.00194\n","Epoch 89/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0026 - mean_absolute_error: 0.0532 - val_loss: 0.0020 - val_mean_absolute_error: 0.0496\n","\n","Epoch 00089: val_loss did not improve from 0.00194\n","Epoch 90/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0029 - mean_absolute_error: 0.0547 - val_loss: 0.0022 - val_mean_absolute_error: 0.0557\n","\n","Epoch 00090: val_loss did not improve from 0.00194\n","Epoch 91/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0030 - mean_absolute_error: 0.0560 - val_loss: 0.0019 - val_mean_absolute_error: 0.0495\n","\n","Epoch 00091: val_loss did not improve from 0.00194\n","Epoch 92/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0027 - mean_absolute_error: 0.0552 - val_loss: 0.0019 - val_mean_absolute_error: 0.0461\n","\n","Epoch 00092: val_loss improved from 0.00194 to 0.00194, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 93/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0028 - mean_absolute_error: 0.0537 - val_loss: 0.0022 - val_mean_absolute_error: 0.0547\n","\n","Epoch 00093: val_loss did not improve from 0.00194\n","Epoch 94/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0523 - val_loss: 0.0019 - val_mean_absolute_error: 0.0486\n","\n","Epoch 00094: val_loss improved from 0.00194 to 0.00192, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 95/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0024 - mean_absolute_error: 0.0506 - val_loss: 0.0022 - val_mean_absolute_error: 0.0540\n","\n","Epoch 00095: val_loss did not improve from 0.00192\n","Epoch 96/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0529 - val_loss: 0.0019 - val_mean_absolute_error: 0.0465\n","\n","Epoch 00096: val_loss improved from 0.00192 to 0.00190, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 97/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0028 - mean_absolute_error: 0.0539 - val_loss: 0.0019 - val_mean_absolute_error: 0.0456\n","\n","Epoch 00097: val_loss did not improve from 0.00190\n","Epoch 98/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0026 - mean_absolute_error: 0.0529 - val_loss: 0.0019 - val_mean_absolute_error: 0.0479\n","\n","Epoch 00098: val_loss improved from 0.00190 to 0.00189, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 99/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0518 - val_loss: 0.0019 - val_mean_absolute_error: 0.0458\n","\n","Epoch 00099: val_loss improved from 0.00189 to 0.00189, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 100/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0509 - val_loss: 0.0019 - val_mean_absolute_error: 0.0475\n","\n","Epoch 00100: val_loss improved from 0.00189 to 0.00188, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 101/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0025 - mean_absolute_error: 0.0527 - val_loss: 0.0021 - val_mean_absolute_error: 0.0535\n","\n","Epoch 00101: val_loss did not improve from 0.00188\n","Epoch 102/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0027 - mean_absolute_error: 0.0545 - val_loss: 0.0020 - val_mean_absolute_error: 0.0458\n","\n","Epoch 00102: val_loss did not improve from 0.00188\n","Epoch 103/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0027 - mean_absolute_error: 0.0556 - val_loss: 0.0024 - val_mean_absolute_error: 0.0483\n","\n","Epoch 00103: val_loss did not improve from 0.00188\n","Epoch 104/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0573 - val_loss: 0.0021 - val_mean_absolute_error: 0.0534\n","\n","Epoch 00104: val_loss did not improve from 0.00188\n","Epoch 105/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0026 - mean_absolute_error: 0.0530 - val_loss: 0.0022 - val_mean_absolute_error: 0.0546\n","\n","Epoch 00105: val_loss did not improve from 0.00188\n","Epoch 106/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0028 - mean_absolute_error: 0.0558 - val_loss: 0.0022 - val_mean_absolute_error: 0.0467\n","\n","Epoch 00106: val_loss did not improve from 0.00188\n","Epoch 107/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0027 - mean_absolute_error: 0.0558 - val_loss: 0.0020 - val_mean_absolute_error: 0.0512\n","\n","Epoch 00107: val_loss did not improve from 0.00188\n","Epoch 108/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0519 - val_loss: 0.0019 - val_mean_absolute_error: 0.0485\n","\n","Epoch 00108: val_loss did not improve from 0.00188\n","Epoch 109/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0025 - mean_absolute_error: 0.0524 - val_loss: 0.0020 - val_mean_absolute_error: 0.0505\n","\n","Epoch 00109: val_loss did not improve from 0.00188\n","Epoch 110/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0500 - val_loss: 0.0019 - val_mean_absolute_error: 0.0462\n","\n","Epoch 00110: val_loss improved from 0.00188 to 0.00185, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 111/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0509 - val_loss: 0.0018 - val_mean_absolute_error: 0.0461\n","\n","Epoch 00111: val_loss improved from 0.00185 to 0.00185, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 112/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0023 - mean_absolute_error: 0.0483 - val_loss: 0.0021 - val_mean_absolute_error: 0.0526\n","\n","Epoch 00112: val_loss did not improve from 0.00185\n","Epoch 113/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_absolute_error: 0.0522 - val_loss: 0.0018 - val_mean_absolute_error: 0.0466\n","\n","Epoch 00113: val_loss improved from 0.00185 to 0.00183, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 114/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0490 - val_loss: 0.0018 - val_mean_absolute_error: 0.0470\n","\n","Epoch 00114: val_loss did not improve from 0.00183\n","Epoch 115/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0528 - val_loss: 0.0024 - val_mean_absolute_error: 0.0566\n","\n","Epoch 00115: val_loss did not improve from 0.00183\n","Epoch 116/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0510 - val_loss: 0.0019 - val_mean_absolute_error: 0.0464\n","\n","Epoch 00116: val_loss did not improve from 0.00183\n","Epoch 117/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0023 - mean_absolute_error: 0.0513 - val_loss: 0.0019 - val_mean_absolute_error: 0.0458\n","\n","Epoch 00117: val_loss did not improve from 0.00183\n","Epoch 118/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0475 - val_loss: 0.0019 - val_mean_absolute_error: 0.0477\n","\n","Epoch 00118: val_loss did not improve from 0.00183\n","Epoch 119/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0022 - mean_absolute_error: 0.0484 - val_loss: 0.0018 - val_mean_absolute_error: 0.0466\n","\n","Epoch 00119: val_loss did not improve from 0.00183\n","Epoch 120/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0026 - mean_absolute_error: 0.0516 - val_loss: 0.0018 - val_mean_absolute_error: 0.0458\n","\n","Epoch 00120: val_loss improved from 0.00183 to 0.00182, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 121/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0022 - mean_absolute_error: 0.0504 - val_loss: 0.0019 - val_mean_absolute_error: 0.0489\n","\n","Epoch 00121: val_loss did not improve from 0.00182\n","Epoch 122/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0022 - mean_absolute_error: 0.0498 - val_loss: 0.0019 - val_mean_absolute_error: 0.0459\n","\n","Epoch 00122: val_loss did not improve from 0.00182\n","Epoch 123/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0025 - mean_absolute_error: 0.0516 - val_loss: 0.0026 - val_mean_absolute_error: 0.0590\n","\n","Epoch 00123: val_loss did not improve from 0.00182\n","Epoch 124/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0533 - val_loss: 0.0018 - val_mean_absolute_error: 0.0465\n","\n","Epoch 00124: val_loss did not improve from 0.00182\n","Epoch 125/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0498 - val_loss: 0.0018 - val_mean_absolute_error: 0.0455\n","\n","Epoch 00125: val_loss improved from 0.00182 to 0.00181, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 126/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0503 - val_loss: 0.0019 - val_mean_absolute_error: 0.0478\n","\n","Epoch 00126: val_loss did not improve from 0.00181\n","Epoch 127/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0023 - mean_absolute_error: 0.0491 - val_loss: 0.0020 - val_mean_absolute_error: 0.0503\n","\n","Epoch 00127: val_loss did not improve from 0.00181\n","Epoch 128/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0512 - val_loss: 0.0018 - val_mean_absolute_error: 0.0465\n","\n","Epoch 00128: val_loss improved from 0.00181 to 0.00179, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 129/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0022 - mean_absolute_error: 0.0495 - val_loss: 0.0020 - val_mean_absolute_error: 0.0507\n","\n","Epoch 00129: val_loss did not improve from 0.00179\n","Epoch 130/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0515 - val_loss: 0.0019 - val_mean_absolute_error: 0.0491\n","\n","Epoch 00130: val_loss did not improve from 0.00179\n","Epoch 131/500\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0025 - mean_absolute_error: 0.0531 - val_loss: 0.0024 - val_mean_absolute_error: 0.0488\n","\n","Epoch 00131: val_loss did not improve from 0.00179\n","Epoch 132/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0024 - mean_absolute_error: 0.0512 - val_loss: 0.0017 - val_mean_absolute_error: 0.0464\n","\n","Epoch 00132: val_loss improved from 0.00179 to 0.00174, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 133/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0026 - mean_absolute_error: 0.0522 - val_loss: 0.0020 - val_mean_absolute_error: 0.0528\n","\n","Epoch 00133: val_loss did not improve from 0.00174\n","Epoch 134/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0024 - mean_absolute_error: 0.0516 - val_loss: 0.0018 - val_mean_absolute_error: 0.0466\n","\n","Epoch 00134: val_loss did not improve from 0.00174\n","Epoch 135/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0019 - mean_absolute_error: 0.0477 - val_loss: 0.0018 - val_mean_absolute_error: 0.0457\n","\n","Epoch 00135: val_loss did not improve from 0.00174\n","Epoch 136/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0021 - mean_absolute_error: 0.0495 - val_loss: 0.0027 - val_mean_absolute_error: 0.0586\n","\n","Epoch 00136: val_loss did not improve from 0.00174\n","Epoch 137/500\n","5/5 [==============================] - 0s 16ms/step - loss: 0.0029 - mean_absolute_error: 0.0559 - val_loss: 0.0022 - val_mean_absolute_error: 0.0547\n","\n","Epoch 00137: val_loss did not improve from 0.00174\n","Epoch 138/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0026 - mean_absolute_error: 0.0561 - val_loss: 0.0020 - val_mean_absolute_error: 0.0449\n","\n","Epoch 00138: val_loss did not improve from 0.00174\n","Epoch 139/500\n","5/5 [==============================] - 0s 16ms/step - loss: 0.0027 - mean_absolute_error: 0.0552 - val_loss: 0.0019 - val_mean_absolute_error: 0.0453\n","\n","Epoch 00139: val_loss did not improve from 0.00174\n","Epoch 140/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0027 - mean_absolute_error: 0.0540 - val_loss: 0.0029 - val_mean_absolute_error: 0.0631\n","\n","Epoch 00140: val_loss did not improve from 0.00174\n","Epoch 141/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0026 - mean_absolute_error: 0.0539 - val_loss: 0.0022 - val_mean_absolute_error: 0.0466\n","\n","Epoch 00141: val_loss did not improve from 0.00174\n","Epoch 142/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0523 - val_loss: 0.0019 - val_mean_absolute_error: 0.0471\n","\n","Epoch 00142: val_loss did not improve from 0.00174\n","Epoch 143/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0500 - val_loss: 0.0023 - val_mean_absolute_error: 0.0552\n","\n","Epoch 00143: val_loss did not improve from 0.00174\n","Epoch 144/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0527 - val_loss: 0.0019 - val_mean_absolute_error: 0.0453\n","\n","Epoch 00144: val_loss did not improve from 0.00174\n","Epoch 145/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0022 - mean_absolute_error: 0.0502 - val_loss: 0.0020 - val_mean_absolute_error: 0.0506\n","\n","Epoch 00145: val_loss did not improve from 0.00174\n","Epoch 146/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0021 - mean_absolute_error: 0.0498 - val_loss: 0.0019 - val_mean_absolute_error: 0.0454\n","\n","Epoch 00146: val_loss did not improve from 0.00174\n","Epoch 147/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0478 - val_loss: 0.0018 - val_mean_absolute_error: 0.0464\n","\n","Epoch 00147: val_loss did not improve from 0.00174\n","Epoch 148/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0469 - val_loss: 0.0021 - val_mean_absolute_error: 0.0536\n","\n","Epoch 00148: val_loss did not improve from 0.00174\n","Epoch 149/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0520 - val_loss: 0.0017 - val_mean_absolute_error: 0.0451\n","\n","Epoch 00149: val_loss did not improve from 0.00174\n","Epoch 150/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0026 - mean_absolute_error: 0.0532 - val_loss: 0.0018 - val_mean_absolute_error: 0.0449\n","\n","Epoch 00150: val_loss did not improve from 0.00174\n","Epoch 151/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0477 - val_loss: 0.0019 - val_mean_absolute_error: 0.0495\n","\n","Epoch 00151: val_loss did not improve from 0.00174\n","Epoch 152/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0490 - val_loss: 0.0017 - val_mean_absolute_error: 0.0462\n","\n","Epoch 00152: val_loss improved from 0.00174 to 0.00173, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 153/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0515 - val_loss: 0.0018 - val_mean_absolute_error: 0.0457\n","\n","Epoch 00153: val_loss did not improve from 0.00173\n","Epoch 154/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0504 - val_loss: 0.0019 - val_mean_absolute_error: 0.0453\n","\n","Epoch 00154: val_loss did not improve from 0.00173\n","Epoch 155/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0534 - val_loss: 0.0017 - val_mean_absolute_error: 0.0452\n","\n","Epoch 00155: val_loss improved from 0.00173 to 0.00169, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 156/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0522 - val_loss: 0.0019 - val_mean_absolute_error: 0.0500\n","\n","Epoch 00156: val_loss did not improve from 0.00169\n","Epoch 157/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0023 - mean_absolute_error: 0.0520 - val_loss: 0.0017 - val_mean_absolute_error: 0.0459\n","\n","Epoch 00157: val_loss improved from 0.00169 to 0.00167, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 158/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0020 - mean_absolute_error: 0.0484 - val_loss: 0.0018 - val_mean_absolute_error: 0.0475\n","\n","Epoch 00158: val_loss did not improve from 0.00167\n","Epoch 159/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0023 - mean_absolute_error: 0.0512 - val_loss: 0.0017 - val_mean_absolute_error: 0.0466\n","\n","Epoch 00159: val_loss did not improve from 0.00167\n","Epoch 160/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0020 - mean_absolute_error: 0.0476 - val_loss: 0.0016 - val_mean_absolute_error: 0.0450\n","\n","Epoch 00160: val_loss improved from 0.00167 to 0.00158, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 161/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0019 - mean_absolute_error: 0.0470 - val_loss: 0.0016 - val_mean_absolute_error: 0.0447\n","\n","Epoch 00161: val_loss improved from 0.00158 to 0.00156, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 162/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0022 - mean_absolute_error: 0.0491 - val_loss: 0.0017 - val_mean_absolute_error: 0.0441\n","\n","Epoch 00162: val_loss did not improve from 0.00156\n","Epoch 163/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0483 - val_loss: 0.0020 - val_mean_absolute_error: 0.0452\n","\n","Epoch 00163: val_loss did not improve from 0.00156\n","Epoch 164/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0023 - mean_absolute_error: 0.0509 - val_loss: 0.0022 - val_mean_absolute_error: 0.0531\n","\n","Epoch 00164: val_loss did not improve from 0.00156\n","Epoch 165/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0023 - mean_absolute_error: 0.0512 - val_loss: 0.0017 - val_mean_absolute_error: 0.0460\n","\n","Epoch 00165: val_loss did not improve from 0.00156\n","Epoch 166/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0479 - val_loss: 0.0019 - val_mean_absolute_error: 0.0452\n","\n","Epoch 00166: val_loss did not improve from 0.00156\n","Epoch 167/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0020 - mean_absolute_error: 0.0498 - val_loss: 0.0018 - val_mean_absolute_error: 0.0444\n","\n","Epoch 00167: val_loss did not improve from 0.00156\n","Epoch 168/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0499 - val_loss: 0.0019 - val_mean_absolute_error: 0.0489\n","\n","Epoch 00168: val_loss did not improve from 0.00156\n","Epoch 169/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0020 - mean_absolute_error: 0.0482 - val_loss: 0.0018 - val_mean_absolute_error: 0.0458\n","\n","Epoch 00169: val_loss did not improve from 0.00156\n","Epoch 170/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0518 - val_loss: 0.0017 - val_mean_absolute_error: 0.0448\n","\n","Epoch 00170: val_loss did not improve from 0.00156\n","Epoch 171/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0021 - mean_absolute_error: 0.0476 - val_loss: 0.0016 - val_mean_absolute_error: 0.0459\n","\n","Epoch 00171: val_loss did not improve from 0.00156\n","Epoch 172/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - mean_absolute_error: 0.0467 - val_loss: 0.0015 - val_mean_absolute_error: 0.0437\n","\n","Epoch 00172: val_loss improved from 0.00156 to 0.00147, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 173/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0017 - mean_absolute_error: 0.0449 - val_loss: 0.0014 - val_mean_absolute_error: 0.0426\n","\n","Epoch 00173: val_loss improved from 0.00147 to 0.00139, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 174/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0019 - mean_absolute_error: 0.0451 - val_loss: 0.0017 - val_mean_absolute_error: 0.0458\n","\n","Epoch 00174: val_loss did not improve from 0.00139\n","Epoch 175/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0463 - val_loss: 0.0014 - val_mean_absolute_error: 0.0425\n","\n","Epoch 00175: val_loss did not improve from 0.00139\n","Epoch 176/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0021 - mean_absolute_error: 0.0484 - val_loss: 0.0022 - val_mean_absolute_error: 0.0542\n","\n","Epoch 00176: val_loss did not improve from 0.00139\n","Epoch 177/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0022 - mean_absolute_error: 0.0492 - val_loss: 0.0015 - val_mean_absolute_error: 0.0423\n","\n","Epoch 00177: val_loss did not improve from 0.00139\n","Epoch 178/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0020 - mean_absolute_error: 0.0468 - val_loss: 0.0014 - val_mean_absolute_error: 0.0393\n","\n","Epoch 00178: val_loss did not improve from 0.00139\n","Epoch 179/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0017 - mean_absolute_error: 0.0433 - val_loss: 0.0014 - val_mean_absolute_error: 0.0416\n","\n","Epoch 00179: val_loss did not improve from 0.00139\n","Epoch 180/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0458 - val_loss: 0.0016 - val_mean_absolute_error: 0.0442\n","\n","Epoch 00180: val_loss did not improve from 0.00139\n","Epoch 181/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0455 - val_loss: 0.0014 - val_mean_absolute_error: 0.0400\n","\n","Epoch 00181: val_loss did not improve from 0.00139\n","Epoch 182/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0018 - mean_absolute_error: 0.0446 - val_loss: 0.0014 - val_mean_absolute_error: 0.0390\n","\n","Epoch 00182: val_loss did not improve from 0.00139\n","Epoch 183/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0018 - mean_absolute_error: 0.0459 - val_loss: 0.0017 - val_mean_absolute_error: 0.0429\n","\n","Epoch 00183: val_loss did not improve from 0.00139\n","Epoch 184/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0018 - mean_absolute_error: 0.0454 - val_loss: 0.0015 - val_mean_absolute_error: 0.0385\n","\n","Epoch 00184: val_loss did not improve from 0.00139\n","Epoch 185/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0417 - val_loss: 0.0013 - val_mean_absolute_error: 0.0419\n","\n","Epoch 00185: val_loss improved from 0.00139 to 0.00131, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 186/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0020 - mean_absolute_error: 0.0478 - val_loss: 0.0018 - val_mean_absolute_error: 0.0429\n","\n","Epoch 00186: val_loss did not improve from 0.00131\n","Epoch 187/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0464 - val_loss: 0.0015 - val_mean_absolute_error: 0.0439\n","\n","Epoch 00187: val_loss did not improve from 0.00131\n","Epoch 188/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0017 - mean_absolute_error: 0.0437 - val_loss: 0.0013 - val_mean_absolute_error: 0.0394\n","\n","Epoch 00188: val_loss improved from 0.00131 to 0.00126, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 189/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0015 - mean_absolute_error: 0.0412 - val_loss: 0.0011 - val_mean_absolute_error: 0.0370\n","\n","Epoch 00189: val_loss improved from 0.00126 to 0.00115, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 190/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0394 - val_loss: 0.0011 - val_mean_absolute_error: 0.0361\n","\n","Epoch 00190: val_loss improved from 0.00115 to 0.00107, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 191/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0417 - val_loss: 0.0012 - val_mean_absolute_error: 0.0406\n","\n","Epoch 00191: val_loss did not improve from 0.00107\n","Epoch 192/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0492 - val_loss: 0.0017 - val_mean_absolute_error: 0.0457\n","\n","Epoch 00192: val_loss did not improve from 0.00107\n","Epoch 193/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0023 - mean_absolute_error: 0.0497 - val_loss: 0.0017 - val_mean_absolute_error: 0.0478\n","\n","Epoch 00193: val_loss did not improve from 0.00107\n","Epoch 194/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0491 - val_loss: 0.0015 - val_mean_absolute_error: 0.0421\n","\n","Epoch 00194: val_loss did not improve from 0.00107\n","Epoch 195/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0503 - val_loss: 0.0017 - val_mean_absolute_error: 0.0416\n","\n","Epoch 00195: val_loss did not improve from 0.00107\n","Epoch 196/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0019 - mean_absolute_error: 0.0472 - val_loss: 0.0015 - val_mean_absolute_error: 0.0464\n","\n","Epoch 00196: val_loss did not improve from 0.00107\n","Epoch 197/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0018 - mean_absolute_error: 0.0466 - val_loss: 0.0014 - val_mean_absolute_error: 0.0421\n","\n","Epoch 00197: val_loss did not improve from 0.00107\n","Epoch 198/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0018 - mean_absolute_error: 0.0457 - val_loss: 0.0015 - val_mean_absolute_error: 0.0403\n","\n","Epoch 00198: val_loss did not improve from 0.00107\n","Epoch 199/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0431 - val_loss: 0.0015 - val_mean_absolute_error: 0.0390\n","\n","Epoch 00199: val_loss did not improve from 0.00107\n","Epoch 200/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0467 - val_loss: 0.0012 - val_mean_absolute_error: 0.0378\n","\n","Epoch 00200: val_loss did not improve from 0.00107\n","Epoch 201/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0420 - val_loss: 0.0016 - val_mean_absolute_error: 0.0412\n","\n","Epoch 00201: val_loss did not improve from 0.00107\n","Epoch 202/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0020 - mean_absolute_error: 0.0477 - val_loss: 0.0012 - val_mean_absolute_error: 0.0394\n","\n","Epoch 00202: val_loss did not improve from 0.00107\n","Epoch 203/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0017 - mean_absolute_error: 0.0446 - val_loss: 0.0011 - val_mean_absolute_error: 0.0350\n","\n","Epoch 00203: val_loss improved from 0.00107 to 0.00107, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 204/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0435 - val_loss: 0.0013 - val_mean_absolute_error: 0.0398\n","\n","Epoch 00204: val_loss did not improve from 0.00107\n","Epoch 205/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0423 - val_loss: 0.0014 - val_mean_absolute_error: 0.0401\n","\n","Epoch 00205: val_loss did not improve from 0.00107\n","Epoch 206/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0451 - val_loss: 0.0012 - val_mean_absolute_error: 0.0402\n","\n","Epoch 00206: val_loss did not improve from 0.00107\n","Epoch 207/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0413 - val_loss: 0.0011 - val_mean_absolute_error: 0.0369\n","\n","Epoch 00207: val_loss improved from 0.00107 to 0.00106, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 208/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0014 - mean_absolute_error: 0.0406 - val_loss: 0.0013 - val_mean_absolute_error: 0.0362\n","\n","Epoch 00208: val_loss did not improve from 0.00106\n","Epoch 209/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0408 - val_loss: 0.0011 - val_mean_absolute_error: 0.0368\n","\n","Epoch 00209: val_loss did not improve from 0.00106\n","Epoch 210/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0433 - val_loss: 0.0011 - val_mean_absolute_error: 0.0349\n","\n","Epoch 00210: val_loss did not improve from 0.00106\n","Epoch 211/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0013 - mean_absolute_error: 0.0392 - val_loss: 0.0011 - val_mean_absolute_error: 0.0359\n","\n","Epoch 00211: val_loss did not improve from 0.00106\n","Epoch 212/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0012 - mean_absolute_error: 0.0366 - val_loss: 9.6092e-04 - val_mean_absolute_error: 0.0348\n","\n","Epoch 00212: val_loss improved from 0.00106 to 0.00096, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 213/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0361 - val_loss: 9.8358e-04 - val_mean_absolute_error: 0.0325\n","\n","Epoch 00213: val_loss did not improve from 0.00096\n","Epoch 214/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0384 - val_loss: 0.0011 - val_mean_absolute_error: 0.0354\n","\n","Epoch 00214: val_loss did not improve from 0.00096\n","Epoch 215/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0013 - mean_absolute_error: 0.0384 - val_loss: 9.7073e-04 - val_mean_absolute_error: 0.0324\n","\n","Epoch 00215: val_loss did not improve from 0.00096\n","Epoch 216/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0371 - val_loss: 0.0010 - val_mean_absolute_error: 0.0344\n","\n","Epoch 00216: val_loss did not improve from 0.00096\n","Epoch 217/500\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0013 - mean_absolute_error: 0.0400 - val_loss: 0.0014 - val_mean_absolute_error: 0.0434\n","\n","Epoch 00217: val_loss did not improve from 0.00096\n","Epoch 218/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0015 - mean_absolute_error: 0.0421 - val_loss: 0.0014 - val_mean_absolute_error: 0.0373\n","\n","Epoch 00218: val_loss did not improve from 0.00096\n","Epoch 219/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0013 - mean_absolute_error: 0.0386 - val_loss: 0.0010 - val_mean_absolute_error: 0.0353\n","\n","Epoch 00219: val_loss did not improve from 0.00096\n","Epoch 220/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0382 - val_loss: 0.0012 - val_mean_absolute_error: 0.0363\n","\n","Epoch 00220: val_loss did not improve from 0.00096\n","Epoch 221/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0403 - val_loss: 0.0017 - val_mean_absolute_error: 0.0466\n","\n","Epoch 00221: val_loss did not improve from 0.00096\n","Epoch 222/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0432 - val_loss: 0.0013 - val_mean_absolute_error: 0.0377\n","\n","Epoch 00222: val_loss did not improve from 0.00096\n","Epoch 223/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0016 - mean_absolute_error: 0.0418 - val_loss: 0.0012 - val_mean_absolute_error: 0.0416\n","\n","Epoch 00223: val_loss did not improve from 0.00096\n","Epoch 224/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0431 - val_loss: 0.0014 - val_mean_absolute_error: 0.0400\n","\n","Epoch 00224: val_loss did not improve from 0.00096\n","Epoch 225/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0370 - val_loss: 0.0013 - val_mean_absolute_error: 0.0365\n","\n","Epoch 00225: val_loss did not improve from 0.00096\n","Epoch 226/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0381 - val_loss: 0.0011 - val_mean_absolute_error: 0.0374\n","\n","Epoch 00226: val_loss did not improve from 0.00096\n","Epoch 227/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0014 - mean_absolute_error: 0.0398 - val_loss: 0.0010 - val_mean_absolute_error: 0.0351\n","\n","Epoch 00227: val_loss did not improve from 0.00096\n","Epoch 228/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0013 - mean_absolute_error: 0.0401 - val_loss: 0.0012 - val_mean_absolute_error: 0.0366\n","\n","Epoch 00228: val_loss did not improve from 0.00096\n","Epoch 229/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0014 - mean_absolute_error: 0.0390 - val_loss: 0.0011 - val_mean_absolute_error: 0.0370\n","\n","Epoch 00229: val_loss did not improve from 0.00096\n","Epoch 230/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0014 - mean_absolute_error: 0.0405 - val_loss: 0.0012 - val_mean_absolute_error: 0.0380\n","\n","Epoch 00230: val_loss did not improve from 0.00096\n","Epoch 231/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0382 - val_loss: 8.7260e-04 - val_mean_absolute_error: 0.0326\n","\n","Epoch 00231: val_loss improved from 0.00096 to 0.00087, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 232/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0011 - mean_absolute_error: 0.0358 - val_loss: 0.0010 - val_mean_absolute_error: 0.0348\n","\n","Epoch 00232: val_loss did not improve from 0.00087\n","Epoch 233/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0381 - val_loss: 0.0010 - val_mean_absolute_error: 0.0338\n","\n","Epoch 00233: val_loss did not improve from 0.00087\n","Epoch 234/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0370 - val_loss: 9.2767e-04 - val_mean_absolute_error: 0.0333\n","\n","Epoch 00234: val_loss did not improve from 0.00087\n","Epoch 235/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0013 - mean_absolute_error: 0.0385 - val_loss: 0.0010 - val_mean_absolute_error: 0.0360\n","\n","Epoch 00235: val_loss did not improve from 0.00087\n","Epoch 236/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0422 - val_loss: 0.0015 - val_mean_absolute_error: 0.0406\n","\n","Epoch 00236: val_loss did not improve from 0.00087\n","Epoch 237/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0015 - mean_absolute_error: 0.0424 - val_loss: 0.0011 - val_mean_absolute_error: 0.0350\n","\n","Epoch 00237: val_loss did not improve from 0.00087\n","Epoch 238/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0420 - val_loss: 9.5047e-04 - val_mean_absolute_error: 0.0328\n","\n","Epoch 00238: val_loss did not improve from 0.00087\n","Epoch 239/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0011 - mean_absolute_error: 0.0371 - val_loss: 0.0012 - val_mean_absolute_error: 0.0385\n","\n","Epoch 00239: val_loss did not improve from 0.00087\n","Epoch 240/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0012 - mean_absolute_error: 0.0385 - val_loss: 9.5854e-04 - val_mean_absolute_error: 0.0326\n","\n","Epoch 00240: val_loss did not improve from 0.00087\n","Epoch 241/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0011 - mean_absolute_error: 0.0356 - val_loss: 9.6151e-04 - val_mean_absolute_error: 0.0333\n","\n","Epoch 00241: val_loss did not improve from 0.00087\n","Epoch 242/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0012 - mean_absolute_error: 0.0374 - val_loss: 9.9127e-04 - val_mean_absolute_error: 0.0339\n","\n","Epoch 00242: val_loss did not improve from 0.00087\n","Epoch 243/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0012 - mean_absolute_error: 0.0376 - val_loss: 8.5822e-04 - val_mean_absolute_error: 0.0332\n","\n","Epoch 00243: val_loss improved from 0.00087 to 0.00086, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 244/500\n","5/5 [==============================] - 0s 26ms/step - loss: 0.0013 - mean_absolute_error: 0.0394 - val_loss: 9.3781e-04 - val_mean_absolute_error: 0.0347\n","\n","Epoch 00244: val_loss did not improve from 0.00086\n","Epoch 245/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0015 - mean_absolute_error: 0.0412 - val_loss: 0.0021 - val_mean_absolute_error: 0.0467\n","\n","Epoch 00245: val_loss did not improve from 0.00086\n","Epoch 246/500\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0020 - mean_absolute_error: 0.0474 - val_loss: 0.0013 - val_mean_absolute_error: 0.0423\n","\n","Epoch 00246: val_loss did not improve from 0.00086\n","Epoch 247/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0015 - mean_absolute_error: 0.0417 - val_loss: 0.0012 - val_mean_absolute_error: 0.0357\n","\n","Epoch 00247: val_loss did not improve from 0.00086\n","Epoch 248/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0015 - mean_absolute_error: 0.0414 - val_loss: 0.0013 - val_mean_absolute_error: 0.0388\n","\n","Epoch 00248: val_loss did not improve from 0.00086\n","Epoch 249/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0016 - mean_absolute_error: 0.0428 - val_loss: 0.0013 - val_mean_absolute_error: 0.0432\n","\n","Epoch 00249: val_loss did not improve from 0.00086\n","Epoch 250/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0396 - val_loss: 0.0011 - val_mean_absolute_error: 0.0345\n","\n","Epoch 00250: val_loss did not improve from 0.00086\n","Epoch 251/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0012 - mean_absolute_error: 0.0368 - val_loss: 9.6549e-04 - val_mean_absolute_error: 0.0348\n","\n","Epoch 00251: val_loss did not improve from 0.00086\n","Epoch 252/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0389 - val_loss: 0.0011 - val_mean_absolute_error: 0.0361\n","\n","Epoch 00252: val_loss did not improve from 0.00086\n","Epoch 253/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0013 - mean_absolute_error: 0.0381 - val_loss: 9.2806e-04 - val_mean_absolute_error: 0.0322\n","\n","Epoch 00253: val_loss did not improve from 0.00086\n","Epoch 254/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0375 - val_loss: 8.8576e-04 - val_mean_absolute_error: 0.0325\n","\n","Epoch 00254: val_loss did not improve from 0.00086\n","Epoch 255/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0011 - mean_absolute_error: 0.0347 - val_loss: 0.0010 - val_mean_absolute_error: 0.0352\n","\n","Epoch 00255: val_loss did not improve from 0.00086\n","Epoch 256/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0371 - val_loss: 8.8017e-04 - val_mean_absolute_error: 0.0306\n","\n","Epoch 00256: val_loss did not improve from 0.00086\n","Epoch 257/500\n","5/5 [==============================] - 0s 16ms/step - loss: 0.0011 - mean_absolute_error: 0.0348 - val_loss: 8.4991e-04 - val_mean_absolute_error: 0.0322\n","\n","Epoch 00257: val_loss improved from 0.00086 to 0.00085, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 258/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - mean_absolute_error: 0.0364 - val_loss: 0.0011 - val_mean_absolute_error: 0.0343\n","\n","Epoch 00258: val_loss did not improve from 0.00085\n","Epoch 259/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0015 - mean_absolute_error: 0.0399 - val_loss: 9.8190e-04 - val_mean_absolute_error: 0.0345\n","\n","Epoch 00259: val_loss did not improve from 0.00085\n","Epoch 260/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0402 - val_loss: 0.0013 - val_mean_absolute_error: 0.0427\n","\n","Epoch 00260: val_loss did not improve from 0.00085\n","Epoch 261/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0395 - val_loss: 0.0015 - val_mean_absolute_error: 0.0409\n","\n","Epoch 00261: val_loss did not improve from 0.00085\n","Epoch 262/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0400 - val_loss: 0.0011 - val_mean_absolute_error: 0.0375\n","\n","Epoch 00262: val_loss did not improve from 0.00085\n","Epoch 263/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0014 - mean_absolute_error: 0.0397 - val_loss: 0.0013 - val_mean_absolute_error: 0.0372\n","\n","Epoch 00263: val_loss did not improve from 0.00085\n","Epoch 264/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0390 - val_loss: 9.2121e-04 - val_mean_absolute_error: 0.0335\n","\n","Epoch 00264: val_loss did not improve from 0.00085\n","Epoch 265/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0012 - mean_absolute_error: 0.0372 - val_loss: 9.0915e-04 - val_mean_absolute_error: 0.0335\n","\n","Epoch 00265: val_loss did not improve from 0.00085\n","Epoch 266/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0358 - val_loss: 9.1540e-04 - val_mean_absolute_error: 0.0326\n","\n","Epoch 00266: val_loss did not improve from 0.00085\n","Epoch 267/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0011 - mean_absolute_error: 0.0363 - val_loss: 9.6434e-04 - val_mean_absolute_error: 0.0324\n","\n","Epoch 00267: val_loss did not improve from 0.00085\n","Epoch 268/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0013 - mean_absolute_error: 0.0369 - val_loss: 8.7265e-04 - val_mean_absolute_error: 0.0337\n","\n","Epoch 00268: val_loss did not improve from 0.00085\n","Epoch 269/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0012 - mean_absolute_error: 0.0376 - val_loss: 0.0010 - val_mean_absolute_error: 0.0327\n","\n","Epoch 00269: val_loss did not improve from 0.00085\n","Epoch 270/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0012 - mean_absolute_error: 0.0374 - val_loss: 9.2953e-04 - val_mean_absolute_error: 0.0324\n","\n","Epoch 00270: val_loss did not improve from 0.00085\n","Epoch 271/500\n","5/5 [==============================] - 0s 20ms/step - loss: 9.9142e-04 - mean_absolute_error: 0.0353 - val_loss: 8.8132e-04 - val_mean_absolute_error: 0.0334\n","\n","Epoch 00271: val_loss did not improve from 0.00085\n","Epoch 272/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0349 - val_loss: 8.8260e-04 - val_mean_absolute_error: 0.0319\n","\n","Epoch 00272: val_loss did not improve from 0.00085\n","Epoch 273/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0011 - mean_absolute_error: 0.0359 - val_loss: 0.0011 - val_mean_absolute_error: 0.0349\n","\n","Epoch 00273: val_loss did not improve from 0.00085\n","Epoch 274/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0011 - mean_absolute_error: 0.0360 - val_loss: 7.8657e-04 - val_mean_absolute_error: 0.0312\n","\n","Epoch 00274: val_loss improved from 0.00085 to 0.00079, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 275/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - mean_absolute_error: 0.0351 - val_loss: 9.4937e-04 - val_mean_absolute_error: 0.0328\n","\n","Epoch 00275: val_loss did not improve from 0.00079\n","Epoch 276/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0010 - mean_absolute_error: 0.0347 - val_loss: 8.4352e-04 - val_mean_absolute_error: 0.0300\n","\n","Epoch 00276: val_loss did not improve from 0.00079\n","Epoch 277/500\n","5/5 [==============================] - 0s 20ms/step - loss: 9.2910e-04 - mean_absolute_error: 0.0331 - val_loss: 8.5149e-04 - val_mean_absolute_error: 0.0321\n","\n","Epoch 00277: val_loss did not improve from 0.00079\n","Epoch 278/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0012 - mean_absolute_error: 0.0353 - val_loss: 8.9460e-04 - val_mean_absolute_error: 0.0315\n","\n","Epoch 00278: val_loss did not improve from 0.00079\n","Epoch 279/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0349 - val_loss: 8.1952e-04 - val_mean_absolute_error: 0.0312\n","\n","Epoch 00279: val_loss did not improve from 0.00079\n","Epoch 280/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0010 - mean_absolute_error: 0.0351 - val_loss: 8.8360e-04 - val_mean_absolute_error: 0.0317\n","\n","Epoch 00280: val_loss did not improve from 0.00079\n","Epoch 281/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0010 - mean_absolute_error: 0.0325 - val_loss: 9.3607e-04 - val_mean_absolute_error: 0.0320\n","\n","Epoch 00281: val_loss did not improve from 0.00079\n","Epoch 282/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0013 - mean_absolute_error: 0.0373 - val_loss: 8.1386e-04 - val_mean_absolute_error: 0.0312\n","\n","Epoch 00282: val_loss did not improve from 0.00079\n","Epoch 283/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0011 - mean_absolute_error: 0.0364 - val_loss: 7.8478e-04 - val_mean_absolute_error: 0.0300\n","\n","Epoch 00283: val_loss improved from 0.00079 to 0.00078, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 284/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0348 - val_loss: 8.5993e-04 - val_mean_absolute_error: 0.0305\n","\n","Epoch 00284: val_loss did not improve from 0.00078\n","Epoch 285/500\n","5/5 [==============================] - 0s 23ms/step - loss: 9.9247e-04 - mean_absolute_error: 0.0331 - val_loss: 0.0010 - val_mean_absolute_error: 0.0335\n","\n","Epoch 00285: val_loss did not improve from 0.00078\n","Epoch 286/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0374 - val_loss: 8.4990e-04 - val_mean_absolute_error: 0.0331\n","\n","Epoch 00286: val_loss did not improve from 0.00078\n","Epoch 287/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0364 - val_loss: 7.9497e-04 - val_mean_absolute_error: 0.0298\n","\n","Epoch 00287: val_loss did not improve from 0.00078\n","Epoch 288/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0011 - mean_absolute_error: 0.0355 - val_loss: 8.4465e-04 - val_mean_absolute_error: 0.0310\n","\n","Epoch 00288: val_loss did not improve from 0.00078\n","Epoch 289/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0010 - mean_absolute_error: 0.0353 - val_loss: 7.0834e-04 - val_mean_absolute_error: 0.0283\n","\n","Epoch 00289: val_loss improved from 0.00078 to 0.00071, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 290/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0367 - val_loss: 0.0011 - val_mean_absolute_error: 0.0351\n","\n","Epoch 00290: val_loss did not improve from 0.00071\n","Epoch 291/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.8383e-04 - mean_absolute_error: 0.0336 - val_loss: 8.9556e-04 - val_mean_absolute_error: 0.0299\n","\n","Epoch 00291: val_loss did not improve from 0.00071\n","Epoch 292/500\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0011 - mean_absolute_error: 0.0347 - val_loss: 8.2931e-04 - val_mean_absolute_error: 0.0319\n","\n","Epoch 00292: val_loss did not improve from 0.00071\n","Epoch 293/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0012 - mean_absolute_error: 0.0364 - val_loss: 9.0661e-04 - val_mean_absolute_error: 0.0322\n","\n","Epoch 00293: val_loss did not improve from 0.00071\n","Epoch 294/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0010 - mean_absolute_error: 0.0345 - val_loss: 0.0012 - val_mean_absolute_error: 0.0354\n","\n","Epoch 00294: val_loss did not improve from 0.00071\n","Epoch 295/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0013 - mean_absolute_error: 0.0369 - val_loss: 8.7576e-04 - val_mean_absolute_error: 0.0325\n","\n","Epoch 00295: val_loss did not improve from 0.00071\n","Epoch 296/500\n","5/5 [==============================] - 0s 17ms/step - loss: 0.0011 - mean_absolute_error: 0.0361 - val_loss: 7.8842e-04 - val_mean_absolute_error: 0.0292\n","\n","Epoch 00296: val_loss did not improve from 0.00071\n","Epoch 297/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0356 - val_loss: 9.3005e-04 - val_mean_absolute_error: 0.0335\n","\n","Epoch 00297: val_loss did not improve from 0.00071\n","Epoch 298/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - mean_absolute_error: 0.0361 - val_loss: 8.5916e-04 - val_mean_absolute_error: 0.0294\n","\n","Epoch 00298: val_loss did not improve from 0.00071\n","Epoch 299/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0337 - val_loss: 9.3072e-04 - val_mean_absolute_error: 0.0338\n","\n","Epoch 00299: val_loss did not improve from 0.00071\n","Epoch 300/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0359 - val_loss: 7.9246e-04 - val_mean_absolute_error: 0.0300\n","\n","Epoch 00300: val_loss did not improve from 0.00071\n","Epoch 301/500\n","5/5 [==============================] - 0s 23ms/step - loss: 9.6473e-04 - mean_absolute_error: 0.0339 - val_loss: 8.8144e-04 - val_mean_absolute_error: 0.0309\n","\n","Epoch 00301: val_loss did not improve from 0.00071\n","Epoch 302/500\n","5/5 [==============================] - 0s 19ms/step - loss: 9.9007e-04 - mean_absolute_error: 0.0339 - val_loss: 8.2940e-04 - val_mean_absolute_error: 0.0319\n","\n","Epoch 00302: val_loss did not improve from 0.00071\n","Epoch 303/500\n","5/5 [==============================] - 0s 20ms/step - loss: 9.6452e-04 - mean_absolute_error: 0.0327 - val_loss: 8.3337e-04 - val_mean_absolute_error: 0.0302\n","\n","Epoch 00303: val_loss did not improve from 0.00071\n","Epoch 304/500\n","5/5 [==============================] - 0s 23ms/step - loss: 9.4640e-04 - mean_absolute_error: 0.0333 - val_loss: 7.5259e-04 - val_mean_absolute_error: 0.0302\n","\n","Epoch 00304: val_loss did not improve from 0.00071\n","Epoch 305/500\n","5/5 [==============================] - 0s 18ms/step - loss: 9.2383e-04 - mean_absolute_error: 0.0332 - val_loss: 8.2223e-04 - val_mean_absolute_error: 0.0306\n","\n","Epoch 00305: val_loss did not improve from 0.00071\n","Epoch 306/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.1562e-04 - mean_absolute_error: 0.0332 - val_loss: 9.0525e-04 - val_mean_absolute_error: 0.0314\n","\n","Epoch 00306: val_loss did not improve from 0.00071\n","Epoch 307/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0011 - mean_absolute_error: 0.0355 - val_loss: 9.4578e-04 - val_mean_absolute_error: 0.0323\n","\n","Epoch 00307: val_loss did not improve from 0.00071\n","Epoch 308/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0010 - mean_absolute_error: 0.0329 - val_loss: 7.6038e-04 - val_mean_absolute_error: 0.0312\n","\n","Epoch 00308: val_loss did not improve from 0.00071\n","Epoch 309/500\n","5/5 [==============================] - 0s 23ms/step - loss: 9.9149e-04 - mean_absolute_error: 0.0338 - val_loss: 7.4630e-04 - val_mean_absolute_error: 0.0293\n","\n","Epoch 00309: val_loss did not improve from 0.00071\n","Epoch 310/500\n","5/5 [==============================] - 0s 20ms/step - loss: 0.0011 - mean_absolute_error: 0.0360 - val_loss: 0.0013 - val_mean_absolute_error: 0.0394\n","\n","Epoch 00310: val_loss did not improve from 0.00071\n","Epoch 311/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0013 - mean_absolute_error: 0.0384 - val_loss: 8.3595e-04 - val_mean_absolute_error: 0.0323\n","\n","Epoch 00311: val_loss did not improve from 0.00071\n","Epoch 312/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0363 - val_loss: 8.5936e-04 - val_mean_absolute_error: 0.0309\n","\n","Epoch 00312: val_loss did not improve from 0.00071\n","Epoch 313/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.2634e-04 - mean_absolute_error: 0.0329 - val_loss: 8.3646e-04 - val_mean_absolute_error: 0.0301\n","\n","Epoch 00313: val_loss did not improve from 0.00071\n","Epoch 314/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0354 - val_loss: 9.2623e-04 - val_mean_absolute_error: 0.0335\n","\n","Epoch 00314: val_loss did not improve from 0.00071\n","Epoch 315/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0014 - mean_absolute_error: 0.0404 - val_loss: 0.0013 - val_mean_absolute_error: 0.0385\n","\n","Epoch 00315: val_loss did not improve from 0.00071\n","Epoch 316/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0014 - mean_absolute_error: 0.0391 - val_loss: 0.0011 - val_mean_absolute_error: 0.0346\n","\n","Epoch 00316: val_loss did not improve from 0.00071\n","Epoch 317/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0014 - mean_absolute_error: 0.0415 - val_loss: 0.0012 - val_mean_absolute_error: 0.0395\n","\n","Epoch 00317: val_loss did not improve from 0.00071\n","Epoch 318/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0014 - mean_absolute_error: 0.0414 - val_loss: 0.0013 - val_mean_absolute_error: 0.0386\n","\n","Epoch 00318: val_loss did not improve from 0.00071\n","Epoch 319/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0016 - mean_absolute_error: 0.0442 - val_loss: 0.0011 - val_mean_absolute_error: 0.0348\n","\n","Epoch 00319: val_loss did not improve from 0.00071\n","Epoch 320/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0012 - mean_absolute_error: 0.0367 - val_loss: 0.0012 - val_mean_absolute_error: 0.0413\n","\n","Epoch 00320: val_loss did not improve from 0.00071\n","Epoch 321/500\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0012 - mean_absolute_error: 0.0375 - val_loss: 0.0011 - val_mean_absolute_error: 0.0343\n","\n","Epoch 00321: val_loss did not improve from 0.00071\n","Epoch 322/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0012 - mean_absolute_error: 0.0373 - val_loss: 9.0166e-04 - val_mean_absolute_error: 0.0310\n","\n","Epoch 00322: val_loss did not improve from 0.00071\n","Epoch 323/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - mean_absolute_error: 0.0332 - val_loss: 9.0563e-04 - val_mean_absolute_error: 0.0337\n","\n","Epoch 00323: val_loss did not improve from 0.00071\n","Epoch 324/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - mean_absolute_error: 0.0344 - val_loss: 7.7563e-04 - val_mean_absolute_error: 0.0290\n","\n","Epoch 00324: val_loss did not improve from 0.00071\n","Epoch 325/500\n","5/5 [==============================] - 0s 18ms/step - loss: 9.8068e-04 - mean_absolute_error: 0.0326 - val_loss: 8.4129e-04 - val_mean_absolute_error: 0.0308\n","\n","Epoch 00325: val_loss did not improve from 0.00071\n","Epoch 326/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0011 - mean_absolute_error: 0.0360 - val_loss: 9.9500e-04 - val_mean_absolute_error: 0.0355\n","\n","Epoch 00326: val_loss did not improve from 0.00071\n","Epoch 327/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.2227e-04 - mean_absolute_error: 0.0324 - val_loss: 8.8216e-04 - val_mean_absolute_error: 0.0307\n","\n","Epoch 00327: val_loss did not improve from 0.00071\n","Epoch 328/500\n","5/5 [==============================] - 0s 24ms/step - loss: 8.8873e-04 - mean_absolute_error: 0.0319 - val_loss: 7.7105e-04 - val_mean_absolute_error: 0.0301\n","\n","Epoch 00328: val_loss did not improve from 0.00071\n","Epoch 329/500\n","5/5 [==============================] - 0s 19ms/step - loss: 8.7602e-04 - mean_absolute_error: 0.0307 - val_loss: 8.1569e-04 - val_mean_absolute_error: 0.0316\n","\n","Epoch 00329: val_loss did not improve from 0.00071\n","Epoch 330/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - mean_absolute_error: 0.0344 - val_loss: 7.6807e-04 - val_mean_absolute_error: 0.0286\n","\n","Epoch 00330: val_loss did not improve from 0.00071\n","Epoch 331/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.3938e-04 - mean_absolute_error: 0.0322 - val_loss: 7.0432e-04 - val_mean_absolute_error: 0.0273\n","\n","Epoch 00331: val_loss improved from 0.00071 to 0.00070, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 332/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.3361e-04 - mean_absolute_error: 0.0327 - val_loss: 7.6787e-04 - val_mean_absolute_error: 0.0288\n","\n","Epoch 00332: val_loss did not improve from 0.00070\n","Epoch 333/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.8564e-04 - mean_absolute_error: 0.0335 - val_loss: 8.8600e-04 - val_mean_absolute_error: 0.0319\n","\n","Epoch 00333: val_loss did not improve from 0.00070\n","Epoch 334/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.1850e-04 - mean_absolute_error: 0.0327 - val_loss: 7.0949e-04 - val_mean_absolute_error: 0.0292\n","\n","Epoch 00334: val_loss did not improve from 0.00070\n","Epoch 335/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.7341e-04 - mean_absolute_error: 0.0313 - val_loss: 8.8714e-04 - val_mean_absolute_error: 0.0309\n","\n","Epoch 00335: val_loss did not improve from 0.00070\n","Epoch 336/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - mean_absolute_error: 0.0341 - val_loss: 6.8715e-04 - val_mean_absolute_error: 0.0284\n","\n","Epoch 00336: val_loss improved from 0.00070 to 0.00069, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 337/500\n","5/5 [==============================] - 0s 18ms/step - loss: 8.2061e-04 - mean_absolute_error: 0.0315 - val_loss: 7.8997e-04 - val_mean_absolute_error: 0.0298\n","\n","Epoch 00337: val_loss did not improve from 0.00069\n","Epoch 338/500\n","5/5 [==============================] - 0s 23ms/step - loss: 9.2544e-04 - mean_absolute_error: 0.0322 - val_loss: 8.2220e-04 - val_mean_absolute_error: 0.0302\n","\n","Epoch 00338: val_loss did not improve from 0.00069\n","Epoch 339/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.4011e-04 - mean_absolute_error: 0.0321 - val_loss: 0.0010 - val_mean_absolute_error: 0.0347\n","\n","Epoch 00339: val_loss did not improve from 0.00069\n","Epoch 340/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0013 - mean_absolute_error: 0.0386 - val_loss: 0.0011 - val_mean_absolute_error: 0.0336\n","\n","Epoch 00340: val_loss did not improve from 0.00069\n","Epoch 341/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0012 - mean_absolute_error: 0.0382 - val_loss: 6.7160e-04 - val_mean_absolute_error: 0.0293\n","\n","Epoch 00341: val_loss improved from 0.00069 to 0.00067, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 342/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0010 - mean_absolute_error: 0.0348 - val_loss: 8.5019e-04 - val_mean_absolute_error: 0.0303\n","\n","Epoch 00342: val_loss did not improve from 0.00067\n","Epoch 343/500\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0011 - mean_absolute_error: 0.0356 - val_loss: 7.8609e-04 - val_mean_absolute_error: 0.0295\n","\n","Epoch 00343: val_loss did not improve from 0.00067\n","Epoch 344/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0011 - mean_absolute_error: 0.0344 - val_loss: 7.0379e-04 - val_mean_absolute_error: 0.0294\n","\n","Epoch 00344: val_loss did not improve from 0.00067\n","Epoch 345/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - mean_absolute_error: 0.0351 - val_loss: 0.0010 - val_mean_absolute_error: 0.0331\n","\n","Epoch 00345: val_loss did not improve from 0.00067\n","Epoch 346/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.5860e-04 - mean_absolute_error: 0.0333 - val_loss: 6.9594e-04 - val_mean_absolute_error: 0.0293\n","\n","Epoch 00346: val_loss did not improve from 0.00067\n","Epoch 347/500\n","5/5 [==============================] - 0s 24ms/step - loss: 8.9341e-04 - mean_absolute_error: 0.0320 - val_loss: 7.3956e-04 - val_mean_absolute_error: 0.0276\n","\n","Epoch 00347: val_loss did not improve from 0.00067\n","Epoch 348/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0343 - val_loss: 7.1993e-04 - val_mean_absolute_error: 0.0282\n","\n","Epoch 00348: val_loss did not improve from 0.00067\n","Epoch 349/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.1547e-04 - mean_absolute_error: 0.0329 - val_loss: 7.1115e-04 - val_mean_absolute_error: 0.0280\n","\n","Epoch 00349: val_loss did not improve from 0.00067\n","Epoch 350/500\n","5/5 [==============================] - 0s 19ms/step - loss: 9.9041e-04 - mean_absolute_error: 0.0332 - val_loss: 7.8172e-04 - val_mean_absolute_error: 0.0291\n","\n","Epoch 00350: val_loss did not improve from 0.00067\n","Epoch 351/500\n","5/5 [==============================] - 0s 20ms/step - loss: 9.8048e-04 - mean_absolute_error: 0.0332 - val_loss: 6.8206e-04 - val_mean_absolute_error: 0.0274\n","\n","Epoch 00351: val_loss did not improve from 0.00067\n","Epoch 352/500\n","5/5 [==============================] - 0s 19ms/step - loss: 8.2611e-04 - mean_absolute_error: 0.0301 - val_loss: 6.4310e-04 - val_mean_absolute_error: 0.0262\n","\n","Epoch 00352: val_loss improved from 0.00067 to 0.00064, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 353/500\n","5/5 [==============================] - 0s 18ms/step - loss: 8.5286e-04 - mean_absolute_error: 0.0309 - val_loss: 8.4734e-04 - val_mean_absolute_error: 0.0304\n","\n","Epoch 00353: val_loss did not improve from 0.00064\n","Epoch 354/500\n","5/5 [==============================] - 0s 18ms/step - loss: 8.9177e-04 - mean_absolute_error: 0.0314 - val_loss: 8.6557e-04 - val_mean_absolute_error: 0.0286\n","\n","Epoch 00354: val_loss did not improve from 0.00064\n","Epoch 355/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0010 - mean_absolute_error: 0.0337 - val_loss: 8.5945e-04 - val_mean_absolute_error: 0.0311\n","\n","Epoch 00355: val_loss did not improve from 0.00064\n","Epoch 356/500\n","5/5 [==============================] - 0s 23ms/step - loss: 9.0171e-04 - mean_absolute_error: 0.0331 - val_loss: 8.3982e-04 - val_mean_absolute_error: 0.0306\n","\n","Epoch 00356: val_loss did not improve from 0.00064\n","Epoch 357/500\n","5/5 [==============================] - 0s 23ms/step - loss: 8.2688e-04 - mean_absolute_error: 0.0315 - val_loss: 6.8825e-04 - val_mean_absolute_error: 0.0274\n","\n","Epoch 00357: val_loss did not improve from 0.00064\n","Epoch 358/500\n","5/5 [==============================] - 0s 18ms/step - loss: 9.0698e-04 - mean_absolute_error: 0.0315 - val_loss: 7.0544e-04 - val_mean_absolute_error: 0.0283\n","\n","Epoch 00358: val_loss did not improve from 0.00064\n","Epoch 359/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0343 - val_loss: 9.7693e-04 - val_mean_absolute_error: 0.0316\n","\n","Epoch 00359: val_loss did not improve from 0.00064\n","Epoch 360/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0010 - mean_absolute_error: 0.0335 - val_loss: 6.8795e-04 - val_mean_absolute_error: 0.0279\n","\n","Epoch 00360: val_loss did not improve from 0.00064\n","Epoch 361/500\n","5/5 [==============================] - 0s 19ms/step - loss: 8.6822e-04 - mean_absolute_error: 0.0311 - val_loss: 7.3295e-04 - val_mean_absolute_error: 0.0284\n","\n","Epoch 00361: val_loss did not improve from 0.00064\n","Epoch 362/500\n","5/5 [==============================] - 0s 18ms/step - loss: 8.1538e-04 - mean_absolute_error: 0.0303 - val_loss: 6.8984e-04 - val_mean_absolute_error: 0.0281\n","\n","Epoch 00362: val_loss did not improve from 0.00064\n","Epoch 363/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.1717e-04 - mean_absolute_error: 0.0302 - val_loss: 6.2732e-04 - val_mean_absolute_error: 0.0275\n","\n","Epoch 00363: val_loss improved from 0.00064 to 0.00063, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 364/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.7547e-04 - mean_absolute_error: 0.0337 - val_loss: 7.9437e-04 - val_mean_absolute_error: 0.0295\n","\n","Epoch 00364: val_loss did not improve from 0.00063\n","Epoch 365/500\n","5/5 [==============================] - 0s 24ms/step - loss: 8.2997e-04 - mean_absolute_error: 0.0306 - val_loss: 6.7257e-04 - val_mean_absolute_error: 0.0282\n","\n","Epoch 00365: val_loss did not improve from 0.00063\n","Epoch 366/500\n","5/5 [==============================] - 0s 26ms/step - loss: 9.8051e-04 - mean_absolute_error: 0.0333 - val_loss: 8.0648e-04 - val_mean_absolute_error: 0.0299\n","\n","Epoch 00366: val_loss did not improve from 0.00063\n","Epoch 367/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.2823e-04 - mean_absolute_error: 0.0339 - val_loss: 7.6434e-04 - val_mean_absolute_error: 0.0310\n","\n","Epoch 00367: val_loss did not improve from 0.00063\n","Epoch 368/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0011 - mean_absolute_error: 0.0344 - val_loss: 7.4002e-04 - val_mean_absolute_error: 0.0297\n","\n","Epoch 00368: val_loss did not improve from 0.00063\n","Epoch 369/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - mean_absolute_error: 0.0346 - val_loss: 8.0631e-04 - val_mean_absolute_error: 0.0312\n","\n","Epoch 00369: val_loss did not improve from 0.00063\n","Epoch 370/500\n","5/5 [==============================] - 0s 18ms/step - loss: 9.9211e-04 - mean_absolute_error: 0.0338 - val_loss: 7.0505e-04 - val_mean_absolute_error: 0.0280\n","\n","Epoch 00370: val_loss did not improve from 0.00063\n","Epoch 371/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.3237e-04 - mean_absolute_error: 0.0291 - val_loss: 6.6054e-04 - val_mean_absolute_error: 0.0280\n","\n","Epoch 00371: val_loss did not improve from 0.00063\n","Epoch 372/500\n","5/5 [==============================] - 0s 23ms/step - loss: 7.0798e-04 - mean_absolute_error: 0.0282 - val_loss: 6.3187e-04 - val_mean_absolute_error: 0.0262\n","\n","Epoch 00372: val_loss did not improve from 0.00063\n","Epoch 373/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.2200e-04 - mean_absolute_error: 0.0325 - val_loss: 6.5304e-04 - val_mean_absolute_error: 0.0276\n","\n","Epoch 00373: val_loss did not improve from 0.00063\n","Epoch 374/500\n","5/5 [==============================] - 0s 19ms/step - loss: 8.4145e-04 - mean_absolute_error: 0.0304 - val_loss: 6.9348e-04 - val_mean_absolute_error: 0.0276\n","\n","Epoch 00374: val_loss did not improve from 0.00063\n","Epoch 375/500\n","5/5 [==============================] - 0s 24ms/step - loss: 8.0860e-04 - mean_absolute_error: 0.0303 - val_loss: 5.8581e-04 - val_mean_absolute_error: 0.0254\n","\n","Epoch 00375: val_loss improved from 0.00063 to 0.00059, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 376/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.2755e-04 - mean_absolute_error: 0.0321 - val_loss: 5.6915e-04 - val_mean_absolute_error: 0.0247\n","\n","Epoch 00376: val_loss improved from 0.00059 to 0.00057, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 377/500\n","5/5 [==============================] - 0s 21ms/step - loss: 8.1421e-04 - mean_absolute_error: 0.0297 - val_loss: 7.5276e-04 - val_mean_absolute_error: 0.0296\n","\n","Epoch 00377: val_loss did not improve from 0.00057\n","Epoch 378/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - mean_absolute_error: 0.0334 - val_loss: 6.0857e-04 - val_mean_absolute_error: 0.0258\n","\n","Epoch 00378: val_loss did not improve from 0.00057\n","Epoch 379/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0011 - mean_absolute_error: 0.0338 - val_loss: 8.8115e-04 - val_mean_absolute_error: 0.0301\n","\n","Epoch 00379: val_loss did not improve from 0.00057\n","Epoch 380/500\n","5/5 [==============================] - 0s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0370 - val_loss: 7.8867e-04 - val_mean_absolute_error: 0.0311\n","\n","Epoch 00380: val_loss did not improve from 0.00057\n","Epoch 381/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0359 - val_loss: 8.4115e-04 - val_mean_absolute_error: 0.0297\n","\n","Epoch 00381: val_loss did not improve from 0.00057\n","Epoch 382/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0011 - mean_absolute_error: 0.0368 - val_loss: 9.4876e-04 - val_mean_absolute_error: 0.0344\n","\n","Epoch 00382: val_loss did not improve from 0.00057\n","Epoch 383/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0338 - val_loss: 8.9645e-04 - val_mean_absolute_error: 0.0308\n","\n","Epoch 00383: val_loss did not improve from 0.00057\n","Epoch 384/500\n","5/5 [==============================] - 0s 21ms/step - loss: 8.9671e-04 - mean_absolute_error: 0.0311 - val_loss: 6.7962e-04 - val_mean_absolute_error: 0.0287\n","\n","Epoch 00384: val_loss did not improve from 0.00057\n","Epoch 385/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.6945e-04 - mean_absolute_error: 0.0299 - val_loss: 7.1002e-04 - val_mean_absolute_error: 0.0270\n","\n","Epoch 00385: val_loss did not improve from 0.00057\n","Epoch 386/500\n","5/5 [==============================] - 0s 23ms/step - loss: 8.4402e-04 - mean_absolute_error: 0.0309 - val_loss: 7.7391e-04 - val_mean_absolute_error: 0.0301\n","\n","Epoch 00386: val_loss did not improve from 0.00057\n","Epoch 387/500\n","5/5 [==============================] - 0s 23ms/step - loss: 9.0549e-04 - mean_absolute_error: 0.0320 - val_loss: 7.7734e-04 - val_mean_absolute_error: 0.0288\n","\n","Epoch 00387: val_loss did not improve from 0.00057\n","Epoch 388/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.7642e-04 - mean_absolute_error: 0.0307 - val_loss: 5.7148e-04 - val_mean_absolute_error: 0.0251\n","\n","Epoch 00388: val_loss did not improve from 0.00057\n","Epoch 389/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.1328e-04 - mean_absolute_error: 0.0296 - val_loss: 7.8670e-04 - val_mean_absolute_error: 0.0288\n","\n","Epoch 00389: val_loss did not improve from 0.00057\n","Epoch 390/500\n","5/5 [==============================] - 0s 21ms/step - loss: 8.1030e-04 - mean_absolute_error: 0.0297 - val_loss: 9.6576e-04 - val_mean_absolute_error: 0.0312\n","\n","Epoch 00390: val_loss did not improve from 0.00057\n","Epoch 391/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0011 - mean_absolute_error: 0.0361 - val_loss: 7.7222e-04 - val_mean_absolute_error: 0.0301\n","\n","Epoch 00391: val_loss did not improve from 0.00057\n","Epoch 392/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.0977e-04 - mean_absolute_error: 0.0324 - val_loss: 7.3988e-04 - val_mean_absolute_error: 0.0282\n","\n","Epoch 00392: val_loss did not improve from 0.00057\n","Epoch 393/500\n","5/5 [==============================] - 0s 21ms/step - loss: 8.3679e-04 - mean_absolute_error: 0.0311 - val_loss: 6.8812e-04 - val_mean_absolute_error: 0.0274\n","\n","Epoch 00393: val_loss did not improve from 0.00057\n","Epoch 394/500\n","5/5 [==============================] - 0s 18ms/step - loss: 9.2122e-04 - mean_absolute_error: 0.0328 - val_loss: 6.2756e-04 - val_mean_absolute_error: 0.0261\n","\n","Epoch 00394: val_loss did not improve from 0.00057\n","Epoch 395/500\n","5/5 [==============================] - 0s 19ms/step - loss: 7.7779e-04 - mean_absolute_error: 0.0297 - val_loss: 6.5754e-04 - val_mean_absolute_error: 0.0269\n","\n","Epoch 00395: val_loss did not improve from 0.00057\n","Epoch 396/500\n","5/5 [==============================] - 0s 24ms/step - loss: 0.0010 - mean_absolute_error: 0.0330 - val_loss: 6.4888e-04 - val_mean_absolute_error: 0.0269\n","\n","Epoch 00396: val_loss did not improve from 0.00057\n","Epoch 397/500\n","5/5 [==============================] - 0s 19ms/step - loss: 7.3065e-04 - mean_absolute_error: 0.0287 - val_loss: 6.5171e-04 - val_mean_absolute_error: 0.0265\n","\n","Epoch 00397: val_loss did not improve from 0.00057\n","Epoch 398/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.6302e-04 - mean_absolute_error: 0.0319 - val_loss: 7.0432e-04 - val_mean_absolute_error: 0.0271\n","\n","Epoch 00398: val_loss did not improve from 0.00057\n","Epoch 399/500\n","5/5 [==============================] - 0s 20ms/step - loss: 8.9495e-04 - mean_absolute_error: 0.0314 - val_loss: 6.2756e-04 - val_mean_absolute_error: 0.0261\n","\n","Epoch 00399: val_loss did not improve from 0.00057\n","Epoch 400/500\n","5/5 [==============================] - 0s 19ms/step - loss: 9.0412e-04 - mean_absolute_error: 0.0316 - val_loss: 7.2326e-04 - val_mean_absolute_error: 0.0280\n","\n","Epoch 00400: val_loss did not improve from 0.00057\n","Epoch 401/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.4905e-04 - mean_absolute_error: 0.0308 - val_loss: 7.2689e-04 - val_mean_absolute_error: 0.0302\n","\n","Epoch 00401: val_loss did not improve from 0.00057\n","Epoch 402/500\n","5/5 [==============================] - 0s 25ms/step - loss: 9.9869e-04 - mean_absolute_error: 0.0344 - val_loss: 9.2696e-04 - val_mean_absolute_error: 0.0332\n","\n","Epoch 00402: val_loss did not improve from 0.00057\n","Epoch 403/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0347 - val_loss: 6.9861e-04 - val_mean_absolute_error: 0.0291\n","\n","Epoch 00403: val_loss did not improve from 0.00057\n","Epoch 404/500\n","5/5 [==============================] - 0s 25ms/step - loss: 8.7328e-04 - mean_absolute_error: 0.0315 - val_loss: 0.0011 - val_mean_absolute_error: 0.0337\n","\n","Epoch 00404: val_loss did not improve from 0.00057\n","Epoch 405/500\n","5/5 [==============================] - 0s 21ms/step - loss: 0.0012 - mean_absolute_error: 0.0347 - val_loss: 6.8895e-04 - val_mean_absolute_error: 0.0272\n","\n","Epoch 00405: val_loss did not improve from 0.00057\n","Epoch 406/500\n","5/5 [==============================] - 0s 23ms/step - loss: 0.0012 - mean_absolute_error: 0.0367 - val_loss: 8.7787e-04 - val_mean_absolute_error: 0.0315\n","\n","Epoch 00406: val_loss did not improve from 0.00057\n","Epoch 407/500\n","5/5 [==============================] - 0s 18ms/step - loss: 9.8348e-04 - mean_absolute_error: 0.0331 - val_loss: 9.7868e-04 - val_mean_absolute_error: 0.0345\n","\n","Epoch 00407: val_loss did not improve from 0.00057\n","Epoch 408/500\n","5/5 [==============================] - 0s 18ms/step - loss: 9.6918e-04 - mean_absolute_error: 0.0334 - val_loss: 6.6372e-04 - val_mean_absolute_error: 0.0282\n","\n","Epoch 00408: val_loss did not improve from 0.00057\n","Epoch 409/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.4815e-04 - mean_absolute_error: 0.0308 - val_loss: 8.3164e-04 - val_mean_absolute_error: 0.0323\n","\n","Epoch 00409: val_loss did not improve from 0.00057\n","Epoch 410/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.7447e-04 - mean_absolute_error: 0.0316 - val_loss: 6.6419e-04 - val_mean_absolute_error: 0.0268\n","\n","Epoch 00410: val_loss did not improve from 0.00057\n","Epoch 411/500\n","5/5 [==============================] - 0s 25ms/step - loss: 0.0010 - mean_absolute_error: 0.0335 - val_loss: 7.1682e-04 - val_mean_absolute_error: 0.0272\n","\n","Epoch 00411: val_loss did not improve from 0.00057\n","Epoch 412/500\n","5/5 [==============================] - 0s 24ms/step - loss: 9.5148e-04 - mean_absolute_error: 0.0325 - val_loss: 8.1930e-04 - val_mean_absolute_error: 0.0325\n","\n","Epoch 00412: val_loss did not improve from 0.00057\n","Epoch 413/500\n","5/5 [==============================] - 0s 23ms/step - loss: 8.8014e-04 - mean_absolute_error: 0.0328 - val_loss: 8.7777e-04 - val_mean_absolute_error: 0.0316\n","\n","Epoch 00413: val_loss did not improve from 0.00057\n","Epoch 414/500\n","5/5 [==============================] - 0s 22ms/step - loss: 0.0010 - mean_absolute_error: 0.0346 - val_loss: 8.5571e-04 - val_mean_absolute_error: 0.0323\n","\n","Epoch 00414: val_loss did not improve from 0.00057\n","Epoch 415/500\n","5/5 [==============================] - 0s 22ms/step - loss: 9.3269e-04 - mean_absolute_error: 0.0328 - val_loss: 7.1068e-04 - val_mean_absolute_error: 0.0270\n","\n","Epoch 00415: val_loss did not improve from 0.00057\n","Epoch 416/500\n","5/5 [==============================] - 0s 19ms/step - loss: 9.0530e-04 - mean_absolute_error: 0.0319 - val_loss: 6.6579e-04 - val_mean_absolute_error: 0.0293\n","\n","Epoch 00416: val_loss did not improve from 0.00057\n","Epoch 417/500\n","5/5 [==============================] - 0s 19ms/step - loss: 9.1642e-04 - mean_absolute_error: 0.0314 - val_loss: 6.7867e-04 - val_mean_absolute_error: 0.0279\n","\n","Epoch 00417: val_loss did not improve from 0.00057\n","Epoch 418/500\n","5/5 [==============================] - 0s 24ms/step - loss: 8.1958e-04 - mean_absolute_error: 0.0303 - val_loss: 6.2703e-04 - val_mean_absolute_error: 0.0271\n","\n","Epoch 00418: val_loss did not improve from 0.00057\n","Epoch 419/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.9922e-04 - mean_absolute_error: 0.0300 - val_loss: 6.5303e-04 - val_mean_absolute_error: 0.0265\n","\n","Epoch 00419: val_loss did not improve from 0.00057\n","Epoch 420/500\n","5/5 [==============================] - 0s 23ms/step - loss: 7.6778e-04 - mean_absolute_error: 0.0284 - val_loss: 5.7558e-04 - val_mean_absolute_error: 0.0264\n","\n","Epoch 00420: val_loss did not improve from 0.00057\n","Epoch 421/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.7122e-04 - mean_absolute_error: 0.0300 - val_loss: 6.9396e-04 - val_mean_absolute_error: 0.0281\n","\n","Epoch 00421: val_loss did not improve from 0.00057\n","Epoch 422/500\n","5/5 [==============================] - 0s 23ms/step - loss: 8.3991e-04 - mean_absolute_error: 0.0310 - val_loss: 5.6261e-04 - val_mean_absolute_error: 0.0255\n","\n","Epoch 00422: val_loss improved from 0.00057 to 0.00056, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 423/500\n","5/5 [==============================] - 0s 21ms/step - loss: 8.1205e-04 - mean_absolute_error: 0.0299 - val_loss: 6.8240e-04 - val_mean_absolute_error: 0.0284\n","\n","Epoch 00423: val_loss did not improve from 0.00056\n","Epoch 424/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.1720e-04 - mean_absolute_error: 0.0290 - val_loss: 5.3167e-04 - val_mean_absolute_error: 0.0248\n","\n","Epoch 00424: val_loss improved from 0.00056 to 0.00053, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 425/500\n","5/5 [==============================] - 0s 19ms/step - loss: 7.3254e-04 - mean_absolute_error: 0.0288 - val_loss: 5.0560e-04 - val_mean_absolute_error: 0.0242\n","\n","Epoch 00425: val_loss improved from 0.00053 to 0.00051, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 426/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.0288e-04 - mean_absolute_error: 0.0274 - val_loss: 5.2669e-04 - val_mean_absolute_error: 0.0242\n","\n","Epoch 00426: val_loss did not improve from 0.00051\n","Epoch 427/500\n","5/5 [==============================] - 0s 23ms/step - loss: 6.6717e-04 - mean_absolute_error: 0.0270 - val_loss: 5.9511e-04 - val_mean_absolute_error: 0.0268\n","\n","Epoch 00427: val_loss did not improve from 0.00051\n","Epoch 428/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.9174e-04 - mean_absolute_error: 0.0336 - val_loss: 5.7541e-04 - val_mean_absolute_error: 0.0243\n","\n","Epoch 00428: val_loss did not improve from 0.00051\n","Epoch 429/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.8264e-04 - mean_absolute_error: 0.0308 - val_loss: 6.4058e-04 - val_mean_absolute_error: 0.0269\n","\n","Epoch 00429: val_loss did not improve from 0.00051\n","Epoch 430/500\n","5/5 [==============================] - 0s 18ms/step - loss: 8.5374e-04 - mean_absolute_error: 0.0314 - val_loss: 7.2419e-04 - val_mean_absolute_error: 0.0286\n","\n","Epoch 00430: val_loss did not improve from 0.00051\n","Epoch 431/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.5966e-04 - mean_absolute_error: 0.0315 - val_loss: 6.9983e-04 - val_mean_absolute_error: 0.0295\n","\n","Epoch 00431: val_loss did not improve from 0.00051\n","Epoch 432/500\n","5/5 [==============================] - 0s 21ms/step - loss: 8.3631e-04 - mean_absolute_error: 0.0309 - val_loss: 8.3829e-04 - val_mean_absolute_error: 0.0300\n","\n","Epoch 00432: val_loss did not improve from 0.00051\n","Epoch 433/500\n","5/5 [==============================] - 0s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0335 - val_loss: 6.3615e-04 - val_mean_absolute_error: 0.0278\n","\n","Epoch 00433: val_loss did not improve from 0.00051\n","Epoch 434/500\n","5/5 [==============================] - 0s 23ms/step - loss: 9.7001e-04 - mean_absolute_error: 0.0334 - val_loss: 8.5428e-04 - val_mean_absolute_error: 0.0317\n","\n","Epoch 00434: val_loss did not improve from 0.00051\n","Epoch 435/500\n","5/5 [==============================] - 0s 21ms/step - loss: 8.0443e-04 - mean_absolute_error: 0.0309 - val_loss: 7.0652e-04 - val_mean_absolute_error: 0.0277\n","\n","Epoch 00435: val_loss did not improve from 0.00051\n","Epoch 436/500\n","5/5 [==============================] - 0s 23ms/step - loss: 7.6720e-04 - mean_absolute_error: 0.0304 - val_loss: 6.9776e-04 - val_mean_absolute_error: 0.0287\n","\n","Epoch 00436: val_loss did not improve from 0.00051\n","Epoch 437/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.8560e-04 - mean_absolute_error: 0.0307 - val_loss: 6.6757e-04 - val_mean_absolute_error: 0.0286\n","\n","Epoch 00437: val_loss did not improve from 0.00051\n","Epoch 438/500\n","5/5 [==============================] - 0s 25ms/step - loss: 7.5992e-04 - mean_absolute_error: 0.0300 - val_loss: 4.7281e-04 - val_mean_absolute_error: 0.0240\n","\n","Epoch 00438: val_loss improved from 0.00051 to 0.00047, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 439/500\n","5/5 [==============================] - 0s 23ms/step - loss: 7.9947e-04 - mean_absolute_error: 0.0295 - val_loss: 6.9628e-04 - val_mean_absolute_error: 0.0267\n","\n","Epoch 00439: val_loss did not improve from 0.00047\n","Epoch 440/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.3728e-04 - mean_absolute_error: 0.0301 - val_loss: 7.3215e-04 - val_mean_absolute_error: 0.0295\n","\n","Epoch 00440: val_loss did not improve from 0.00047\n","Epoch 441/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.7450e-04 - mean_absolute_error: 0.0322 - val_loss: 7.3049e-04 - val_mean_absolute_error: 0.0280\n","\n","Epoch 00441: val_loss did not improve from 0.00047\n","Epoch 442/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.3380e-04 - mean_absolute_error: 0.0286 - val_loss: 6.5900e-04 - val_mean_absolute_error: 0.0285\n","\n","Epoch 00442: val_loss did not improve from 0.00047\n","Epoch 443/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.8599e-04 - mean_absolute_error: 0.0297 - val_loss: 6.0084e-04 - val_mean_absolute_error: 0.0262\n","\n","Epoch 00443: val_loss did not improve from 0.00047\n","Epoch 444/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.4476e-04 - mean_absolute_error: 0.0305 - val_loss: 5.4313e-04 - val_mean_absolute_error: 0.0253\n","\n","Epoch 00444: val_loss did not improve from 0.00047\n","Epoch 445/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.6280e-04 - mean_absolute_error: 0.0286 - val_loss: 4.7753e-04 - val_mean_absolute_error: 0.0236\n","\n","Epoch 00445: val_loss did not improve from 0.00047\n","Epoch 446/500\n","5/5 [==============================] - 0s 24ms/step - loss: 7.2900e-04 - mean_absolute_error: 0.0291 - val_loss: 5.2520e-04 - val_mean_absolute_error: 0.0249\n","\n","Epoch 00446: val_loss did not improve from 0.00047\n","Epoch 447/500\n","5/5 [==============================] - 0s 23ms/step - loss: 7.2955e-04 - mean_absolute_error: 0.0290 - val_loss: 6.0172e-04 - val_mean_absolute_error: 0.0273\n","\n","Epoch 00447: val_loss did not improve from 0.00047\n","Epoch 448/500\n","5/5 [==============================] - 0s 26ms/step - loss: 6.9689e-04 - mean_absolute_error: 0.0283 - val_loss: 5.3993e-04 - val_mean_absolute_error: 0.0246\n","\n","Epoch 00448: val_loss did not improve from 0.00047\n","Epoch 449/500\n","5/5 [==============================] - 0s 20ms/step - loss: 7.7738e-04 - mean_absolute_error: 0.0289 - val_loss: 5.6889e-04 - val_mean_absolute_error: 0.0252\n","\n","Epoch 00449: val_loss did not improve from 0.00047\n","Epoch 450/500\n","5/5 [==============================] - 0s 24ms/step - loss: 7.0393e-04 - mean_absolute_error: 0.0281 - val_loss: 4.5173e-04 - val_mean_absolute_error: 0.0234\n","\n","Epoch 00450: val_loss improved from 0.00047 to 0.00045, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 451/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.2777e-04 - mean_absolute_error: 0.0287 - val_loss: 7.1444e-04 - val_mean_absolute_error: 0.0278\n","\n","Epoch 00451: val_loss did not improve from 0.00045\n","Epoch 452/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.4463e-04 - mean_absolute_error: 0.0298 - val_loss: 6.4693e-04 - val_mean_absolute_error: 0.0279\n","\n","Epoch 00452: val_loss did not improve from 0.00045\n","Epoch 453/500\n","5/5 [==============================] - 0s 21ms/step - loss: 9.8626e-04 - mean_absolute_error: 0.0336 - val_loss: 9.1312e-04 - val_mean_absolute_error: 0.0328\n","\n","Epoch 00453: val_loss did not improve from 0.00045\n","Epoch 454/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.9754e-04 - mean_absolute_error: 0.0306 - val_loss: 5.2229e-04 - val_mean_absolute_error: 0.0250\n","\n","Epoch 00454: val_loss did not improve from 0.00045\n","Epoch 455/500\n","5/5 [==============================] - 0s 23ms/step - loss: 7.7321e-04 - mean_absolute_error: 0.0276 - val_loss: 5.5004e-04 - val_mean_absolute_error: 0.0240\n","\n","Epoch 00455: val_loss did not improve from 0.00045\n","Epoch 456/500\n","5/5 [==============================] - 0s 23ms/step - loss: 6.6512e-04 - mean_absolute_error: 0.0277 - val_loss: 5.3596e-04 - val_mean_absolute_error: 0.0248\n","\n","Epoch 00456: val_loss did not improve from 0.00045\n","Epoch 457/500\n","5/5 [==============================] - 0s 21ms/step - loss: 6.9264e-04 - mean_absolute_error: 0.0287 - val_loss: 4.7974e-04 - val_mean_absolute_error: 0.0233\n","\n","Epoch 00457: val_loss did not improve from 0.00045\n","Epoch 458/500\n","5/5 [==============================] - 0s 23ms/step - loss: 6.4816e-04 - mean_absolute_error: 0.0272 - val_loss: 5.5697e-04 - val_mean_absolute_error: 0.0247\n","\n","Epoch 00458: val_loss did not improve from 0.00045\n","Epoch 459/500\n","5/5 [==============================] - 0s 19ms/step - loss: 7.4789e-04 - mean_absolute_error: 0.0297 - val_loss: 6.3099e-04 - val_mean_absolute_error: 0.0278\n","\n","Epoch 00459: val_loss did not improve from 0.00045\n","Epoch 460/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.4542e-04 - mean_absolute_error: 0.0276 - val_loss: 6.3139e-04 - val_mean_absolute_error: 0.0259\n","\n","Epoch 00460: val_loss did not improve from 0.00045\n","Epoch 461/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.2322e-04 - mean_absolute_error: 0.0277 - val_loss: 5.3301e-04 - val_mean_absolute_error: 0.0251\n","\n","Epoch 00461: val_loss did not improve from 0.00045\n","Epoch 462/500\n","5/5 [==============================] - 0s 22ms/step - loss: 8.1961e-04 - mean_absolute_error: 0.0301 - val_loss: 6.4591e-04 - val_mean_absolute_error: 0.0264\n","\n","Epoch 00462: val_loss did not improve from 0.00045\n","Epoch 463/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.9997e-04 - mean_absolute_error: 0.0303 - val_loss: 6.2360e-04 - val_mean_absolute_error: 0.0283\n","\n","Epoch 00463: val_loss did not improve from 0.00045\n","Epoch 464/500\n","5/5 [==============================] - 0s 24ms/step - loss: 8.4601e-04 - mean_absolute_error: 0.0307 - val_loss: 6.0144e-04 - val_mean_absolute_error: 0.0272\n","\n","Epoch 00464: val_loss did not improve from 0.00045\n","Epoch 465/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.6700e-04 - mean_absolute_error: 0.0299 - val_loss: 5.6353e-04 - val_mean_absolute_error: 0.0254\n","\n","Epoch 00465: val_loss did not improve from 0.00045\n","Epoch 466/500\n","5/5 [==============================] - 0s 18ms/step - loss: 6.8512e-04 - mean_absolute_error: 0.0281 - val_loss: 5.2445e-04 - val_mean_absolute_error: 0.0244\n","\n","Epoch 00466: val_loss did not improve from 0.00045\n","Epoch 467/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.0972e-04 - mean_absolute_error: 0.0283 - val_loss: 5.3829e-04 - val_mean_absolute_error: 0.0247\n","\n","Epoch 00467: val_loss did not improve from 0.00045\n","Epoch 468/500\n","5/5 [==============================] - 0s 22ms/step - loss: 6.0648e-04 - mean_absolute_error: 0.0272 - val_loss: 5.3115e-04 - val_mean_absolute_error: 0.0244\n","\n","Epoch 00468: val_loss did not improve from 0.00045\n","Epoch 469/500\n","5/5 [==============================] - 0s 22ms/step - loss: 6.8305e-04 - mean_absolute_error: 0.0283 - val_loss: 5.8813e-04 - val_mean_absolute_error: 0.0260\n","\n","Epoch 00469: val_loss did not improve from 0.00045\n","Epoch 470/500\n","5/5 [==============================] - 0s 19ms/step - loss: 7.0310e-04 - mean_absolute_error: 0.0283 - val_loss: 4.8679e-04 - val_mean_absolute_error: 0.0249\n","\n","Epoch 00470: val_loss did not improve from 0.00045\n","Epoch 471/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.9058e-04 - mean_absolute_error: 0.0297 - val_loss: 5.5527e-04 - val_mean_absolute_error: 0.0256\n","\n","Epoch 00471: val_loss did not improve from 0.00045\n","Epoch 472/500\n","5/5 [==============================] - 0s 20ms/step - loss: 7.2557e-04 - mean_absolute_error: 0.0285 - val_loss: 6.2323e-04 - val_mean_absolute_error: 0.0263\n","\n","Epoch 00472: val_loss did not improve from 0.00045\n","Epoch 473/500\n","5/5 [==============================] - 0s 24ms/step - loss: 7.4691e-04 - mean_absolute_error: 0.0285 - val_loss: 5.3512e-04 - val_mean_absolute_error: 0.0241\n","\n","Epoch 00473: val_loss did not improve from 0.00045\n","Epoch 474/500\n","5/5 [==============================] - 0s 18ms/step - loss: 6.1070e-04 - mean_absolute_error: 0.0263 - val_loss: 5.6733e-04 - val_mean_absolute_error: 0.0262\n","\n","Epoch 00474: val_loss did not improve from 0.00045\n","Epoch 475/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.7109e-04 - mean_absolute_error: 0.0294 - val_loss: 5.7598e-04 - val_mean_absolute_error: 0.0259\n","\n","Epoch 00475: val_loss did not improve from 0.00045\n","Epoch 476/500\n","5/5 [==============================] - 0s 21ms/step - loss: 7.1284e-04 - mean_absolute_error: 0.0301 - val_loss: 5.8289e-04 - val_mean_absolute_error: 0.0281\n","\n","Epoch 00476: val_loss did not improve from 0.00045\n","Epoch 477/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.3573e-04 - mean_absolute_error: 0.0289 - val_loss: 4.6001e-04 - val_mean_absolute_error: 0.0229\n","\n","Epoch 00477: val_loss did not improve from 0.00045\n","Epoch 478/500\n","5/5 [==============================] - 0s 24ms/step - loss: 7.3262e-04 - mean_absolute_error: 0.0299 - val_loss: 4.6920e-04 - val_mean_absolute_error: 0.0230\n","\n","Epoch 00478: val_loss did not improve from 0.00045\n","Epoch 479/500\n","5/5 [==============================] - 0s 24ms/step - loss: 7.6582e-04 - mean_absolute_error: 0.0307 - val_loss: 6.6577e-04 - val_mean_absolute_error: 0.0276\n","\n","Epoch 00479: val_loss did not improve from 0.00045\n","Epoch 480/500\n","5/5 [==============================] - 0s 23ms/step - loss: 7.2311e-04 - mean_absolute_error: 0.0292 - val_loss: 4.7837e-04 - val_mean_absolute_error: 0.0236\n","\n","Epoch 00480: val_loss did not improve from 0.00045\n","Epoch 481/500\n","5/5 [==============================] - 0s 19ms/step - loss: 7.5254e-04 - mean_absolute_error: 0.0285 - val_loss: 5.0253e-04 - val_mean_absolute_error: 0.0231\n","\n","Epoch 00481: val_loss did not improve from 0.00045\n","Epoch 482/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.0594e-04 - mean_absolute_error: 0.0284 - val_loss: 5.8723e-04 - val_mean_absolute_error: 0.0258\n","\n","Epoch 00482: val_loss did not improve from 0.00045\n","Epoch 483/500\n","5/5 [==============================] - 0s 18ms/step - loss: 6.5999e-04 - mean_absolute_error: 0.0280 - val_loss: 4.8647e-04 - val_mean_absolute_error: 0.0235\n","\n","Epoch 00483: val_loss did not improve from 0.00045\n","Epoch 484/500\n","5/5 [==============================] - 0s 18ms/step - loss: 8.7627e-04 - mean_absolute_error: 0.0311 - val_loss: 4.2566e-04 - val_mean_absolute_error: 0.0222\n","\n","Epoch 00484: val_loss improved from 0.00045 to 0.00043, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 485/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.2606e-04 - mean_absolute_error: 0.0289 - val_loss: 5.4193e-04 - val_mean_absolute_error: 0.0249\n","\n","Epoch 00485: val_loss did not improve from 0.00043\n","Epoch 486/500\n","5/5 [==============================] - 0s 22ms/step - loss: 6.7057e-04 - mean_absolute_error: 0.0277 - val_loss: 4.7446e-04 - val_mean_absolute_error: 0.0242\n","\n","Epoch 00486: val_loss did not improve from 0.00043\n","Epoch 487/500\n","5/5 [==============================] - 0s 26ms/step - loss: 6.4801e-04 - mean_absolute_error: 0.0277 - val_loss: 5.9561e-04 - val_mean_absolute_error: 0.0257\n","\n","Epoch 00487: val_loss did not improve from 0.00043\n","Epoch 488/500\n","5/5 [==============================] - 0s 22ms/step - loss: 6.9678e-04 - mean_absolute_error: 0.0283 - val_loss: 4.9718e-04 - val_mean_absolute_error: 0.0247\n","\n","Epoch 00488: val_loss did not improve from 0.00043\n","Epoch 489/500\n","5/5 [==============================] - 0s 21ms/step - loss: 6.4720e-04 - mean_absolute_error: 0.0267 - val_loss: 5.7701e-04 - val_mean_absolute_error: 0.0258\n","\n","Epoch 00489: val_loss did not improve from 0.00043\n","Epoch 490/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.4071e-04 - mean_absolute_error: 0.0284 - val_loss: 3.7405e-04 - val_mean_absolute_error: 0.0208\n","\n","Epoch 00490: val_loss improved from 0.00043 to 0.00037, saving model to results/2021-06-13_NVDA-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n","Epoch 491/500\n","5/5 [==============================] - 0s 24ms/step - loss: 6.7357e-04 - mean_absolute_error: 0.0270 - val_loss: 4.4543e-04 - val_mean_absolute_error: 0.0225\n","\n","Epoch 00491: val_loss did not improve from 0.00037\n","Epoch 492/500\n","5/5 [==============================] - 0s 18ms/step - loss: 7.7179e-04 - mean_absolute_error: 0.0298 - val_loss: 4.9770e-04 - val_mean_absolute_error: 0.0253\n","\n","Epoch 00492: val_loss did not improve from 0.00037\n","Epoch 493/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.4591e-04 - mean_absolute_error: 0.0290 - val_loss: 5.1933e-04 - val_mean_absolute_error: 0.0236\n","\n","Epoch 00493: val_loss did not improve from 0.00037\n","Epoch 494/500\n","5/5 [==============================] - 0s 18ms/step - loss: 6.0410e-04 - mean_absolute_error: 0.0252 - val_loss: 4.8946e-04 - val_mean_absolute_error: 0.0246\n","\n","Epoch 00494: val_loss did not improve from 0.00037\n","Epoch 495/500\n","5/5 [==============================] - 0s 22ms/step - loss: 6.4097e-04 - mean_absolute_error: 0.0273 - val_loss: 8.3247e-04 - val_mean_absolute_error: 0.0307\n","\n","Epoch 00495: val_loss did not improve from 0.00037\n","Epoch 496/500\n","5/5 [==============================] - 0s 23ms/step - loss: 8.0070e-04 - mean_absolute_error: 0.0301 - val_loss: 4.5616e-04 - val_mean_absolute_error: 0.0235\n","\n","Epoch 00496: val_loss did not improve from 0.00037\n","Epoch 497/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.3940e-04 - mean_absolute_error: 0.0292 - val_loss: 4.6508e-04 - val_mean_absolute_error: 0.0228\n","\n","Epoch 00497: val_loss did not improve from 0.00037\n","Epoch 498/500\n","5/5 [==============================] - 0s 22ms/step - loss: 6.9768e-04 - mean_absolute_error: 0.0285 - val_loss: 6.5185e-04 - val_mean_absolute_error: 0.0278\n","\n","Epoch 00498: val_loss did not improve from 0.00037\n","Epoch 499/500\n","5/5 [==============================] - 0s 22ms/step - loss: 7.2997e-04 - mean_absolute_error: 0.0290 - val_loss: 5.2985e-04 - val_mean_absolute_error: 0.0247\n","\n","Epoch 00499: val_loss did not improve from 0.00037\n","Epoch 500/500\n","5/5 [==============================] - 0s 26ms/step - loss: 7.2406e-04 - mean_absolute_error: 0.0291 - val_loss: 5.1237e-04 - val_mean_absolute_error: 0.0236\n","\n","Epoch 00500: val_loss did not improve from 0.00037\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234},"id":"dYpWm5m2Hh0-","executionInfo":{"status":"ok","timestamp":1623555490862,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}},"outputId":"9ff2ec9b-ee86-4a49-fed6-458bd7196c96"},"source":["data[\"df\"].tail()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>adjclose</th>\n","      <th>volume</th>\n","      <th>open</th>\n","      <th>high</th>\n","      <th>low</th>\n","    </tr>\n","    <tr>\n","      <th>Date</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2021-06-07</th>\n","      <td>704.598511</td>\n","      <td>14393900</td>\n","      <td>702.849976</td>\n","      <td>712.500000</td>\n","      <td>687.710022</td>\n","    </tr>\n","    <tr>\n","      <th>2021-06-08</th>\n","      <td>698.120056</td>\n","      <td>8096200</td>\n","      <td>701.090027</td>\n","      <td>704.859985</td>\n","      <td>690.039978</td>\n","    </tr>\n","    <tr>\n","      <th>2021-06-09</th>\n","      <td>694.330017</td>\n","      <td>9541400</td>\n","      <td>700.630005</td>\n","      <td>703.000000</td>\n","      <td>690.229980</td>\n","    </tr>\n","    <tr>\n","      <th>2021-06-10</th>\n","      <td>697.000000</td>\n","      <td>7194300</td>\n","      <td>694.000000</td>\n","      <td>699.679993</td>\n","      <td>687.039978</td>\n","    </tr>\n","    <tr>\n","      <th>2021-06-11</th>\n","      <td>713.010010</td>\n","      <td>10391900</td>\n","      <td>699.179993</td>\n","      <td>717.570007</td>\n","      <td>697.750000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              adjclose    volume        open        high         low\n","Date                                                                \n","2021-06-07  704.598511  14393900  702.849976  712.500000  687.710022\n","2021-06-08  698.120056   8096200  701.090027  704.859985  690.039978\n","2021-06-09  694.330017   9541400  700.630005  703.000000  690.229980\n","2021-06-10  697.000000   7194300  694.000000  699.679993  687.039978\n","2021-06-11  713.010010  10391900  699.179993  717.570007  697.750000"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"WxGvYCIMFrLG"},"source":["# 6. Plotting predictions from the network"]},{"cell_type":"code","metadata":{"id":"0-6Cea6mFrLG","executionInfo":{"status":"ok","timestamp":1623555490863,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# !tensorboard --logdir=\"logs\""],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lHp6QOVdTuyJ"},"source":["# 7. Testing the Model"]},{"cell_type":"code","metadata":{"id":"IvhQ09LjPkhb","executionInfo":{"status":"ok","timestamp":1623555490863,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["import matplotlib.pyplot as plt\n","\n","def plot_graph(test_df):\n","    \"\"\"\n","    This function plots true close price along with predicted close price\n","    with blue and red colors respectively\n","    \"\"\"\n","    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n","    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n","    plt.xlabel(\"Days\")\n","    plt.ylabel(\"Price\")\n","    plt.legend([\"Actual Price\", \"Predicted Price\"])\n","    plt.show()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Da_OAttPntO","executionInfo":{"status":"ok","timestamp":1623555490864,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["def get_final_df(model, data):\n","    \"\"\"\n","    This function takes the `model` and `data` dict to \n","    construct a final dataframe that includes the features along \n","    with true and predicted prices of the testing dataset\n","    \"\"\"\n","    # if predicted future price is higher than the current, \n","    # then calculate the true future price minus the current price, to get the buy profit\n","    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n","    # if the predicted future price is lower than the current price,\n","    # then subtract the true future price from the current price\n","    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n","    X_test = data[\"X_test\"]\n","    y_test = data[\"y_test\"]\n","    # perform prediction and get prices\n","    y_pred = model.predict(X_test)\n","    if SCALE:\n","        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n","        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n","    test_df = data[\"test_df\"]\n","    # add predicted future prices to the dataframe\n","    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n","    # add true future prices to the dataframe\n","    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n","    # sort the dataframe by date\n","    test_df.sort_index(inplace=True)\n","    final_df = test_df\n","    # add the buy profit column\n","    final_df[\"buy_profit\"] = list(map(buy_profit, \n","                                    final_df[\"adjclose\"], \n","                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n","                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n","                                    # since we don't have profit for last sequence, add 0's\n","                                    )\n","    # add the sell profit column\n","    final_df[\"sell_profit\"] = list(map(sell_profit, \n","                                    final_df[\"adjclose\"], \n","                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n","                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n","                                    # since we don't have profit for last sequence, add 0's\n","                                    )\n","    return final_df"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"TuhQVRjtPqWv","executionInfo":{"status":"ok","timestamp":1623555490864,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["def predict(model, data):\n","    # retrieve the last sequence from data\n","    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n","    # expand dimension\n","    last_sequence = np.expand_dims(last_sequence, axis=0)\n","    # get the prediction (scaled from 0 to 1)\n","    prediction = model.predict(last_sequence)\n","    # get the price (by inverting the scaling)\n","    if SCALE:\n","        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n","    else:\n","        predicted_price = prediction[0][0]\n","    return predicted_price"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"odXR1ToKPsxg","executionInfo":{"status":"ok","timestamp":1623555490864,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# load optimal model weights from results folder\n","model_path = os.path.join(\"results\", model_name) + \".h5\"\n","model.load_weights(model_path)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"1OrgnuaPPvlB","executionInfo":{"status":"ok","timestamp":1623555490865,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# evaluate the model\n","loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n","# calculate the mean absolute error (inverse scaling)\n","if SCALE:\n","    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n","else:\n","    mean_absolute_error = mae"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"U09agAo5PzfC","executionInfo":{"status":"ok","timestamp":1623555491480,"user_tz":-540,"elapsed":625,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# get the final dataframe for the testing set\n","final_df = get_final_df(model, data)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQBdklxEP24V","executionInfo":{"status":"ok","timestamp":1623555491986,"user_tz":-540,"elapsed":509,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# predict the future price\n","future_price = predict(model, data)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"DcAMCdIQP6Fu","executionInfo":{"status":"ok","timestamp":1623555491987,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# we calculate the accuracy by counting the number of positive profits\n","accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n","# calculating total buy & sell profit\n","total_buy_profit  = final_df[\"buy_profit\"].sum()\n","total_sell_profit = final_df[\"sell_profit\"].sum()\n","# total profit by adding sell & buy together\n","total_profit = total_buy_profit + total_sell_profit\n","# dividing total profit by number of testing samples (number of trades)\n","profit_per_trade = total_profit / len(final_df)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"U4t4m7LxP8XA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623555491987,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}},"outputId":"5f2524fe-4895-4708-abbf-ae405e154bd6"},"source":["# printing metrics\n","print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n","print(f\"{LOSS} loss:\", loss)\n","print(\"Mean Absolute Error:\", mean_absolute_error)\n","print(\"Accuracy score:\", accuracy_score)\n","print(\"Total buy profit:\", total_buy_profit)\n","print(\"Total sell profit:\", total_sell_profit)\n","print(\"Total profit:\", total_profit)\n","print(\"Profit per trade:\", profit_per_trade)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Future price after 15 days is 615.12$\n","huber_loss loss: 0.0003740520915016532\n","Mean Absolute Error: 175.10245398961342\n","Accuracy score: 0.8311688311688312\n","Total buy profit: 1825.2220153808594\n","Total sell profit: 757.3129119873047\n","Total profit: 2582.534927368164\n","Profit per trade: 33.53941464114499\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tJeSuwYTP--8","colab":{"base_uri":"https://localhost:8080/","height":278},"executionInfo":{"status":"ok","timestamp":1623555491988,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}},"outputId":"94ab2816-878a-44cb-da29-c4169466e51b"},"source":["# plot true/pred prices graph\n","plot_graph(final_df)"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"O_KVamSiVD00"},"source":["# 9. Model Measurement"]},{"cell_type":"code","metadata":{"id":"0wd_-_MtVFer","executionInfo":{"status":"ok","timestamp":1623555491988,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}}},"source":["# we calculate the accuracy by counting the number of positive profits\n","accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n","# calculating total buy & sell profit\n","total_buy_profit  = final_df[\"buy_profit\"].sum()\n","total_sell_profit = final_df[\"sell_profit\"].sum()\n","# total profit by adding sell & buy together\n","total_profit = total_buy_profit + total_sell_profit\n","# dividing total profit by number of testing samples (number of trades)\n","profit_per_trade = total_profit / len(final_df)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"yru6IKOhVO9v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623555491989,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}},"outputId":"58608a5f-5660-4746-e1b1-f6b46128456e"},"source":["# printing metrics\n","print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n","print(f\"{LOSS} loss:\", loss)\n","print(\"Mean Absolute Error:\", mean_absolute_error)\n","print(\"Accuracy score:\", accuracy_score)\n","print(\"Total buy profit:\", total_buy_profit)\n","print(\"Total sell profit:\", total_sell_profit)\n","print(\"Total profit:\", total_profit)\n","print(\"Profit per trade:\", profit_per_trade)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Future price after 15 days is 615.12$\n","huber_loss loss: 0.0003740520915016532\n","Mean Absolute Error: 175.10245398961342\n","Accuracy score: 0.8311688311688312\n","Total buy profit: 1825.2220153808594\n","Total sell profit: 757.3129119873047\n","Total profit: 2582.534927368164\n","Profit per trade: 33.53941464114499\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0b6mSzEPVP2n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623555491989,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hyeri Park","photoUrl":"","userId":"17801311397895611660"}},"outputId":"e11a3406-6768-406e-8deb-a8a23c86ec4d"},"source":["print(final_df.tail(10))\n","# save the final dataframe to csv-results folder\n","csv_results_folder = \"csv-results\"\n","if not os.path.isdir(csv_results_folder):\n","    os.mkdir(csv_results_folder)\n","csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n","final_df.to_csv(csv_filename)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["              adjclose    volume  ...  buy_profit  sell_profit\n","Date                              ...                         \n","2021-03-05  498.173828  13571000  ...   15.278503     0.000000\n","2021-03-08  463.463806  13577800  ...   54.347534     0.000000\n","2021-03-18  508.783386   7347400  ...   67.084656     0.000000\n","2021-03-24  505.604126   6146000  ...  139.737976     0.000000\n","2021-04-12  608.220581  21733100  ...    0.000000    14.886597\n","2021-04-16  636.354187   8380200  ...    0.000000    43.999939\n","2021-04-26  618.978149   4944900  ...    0.000000    52.487976\n","2021-05-03  593.333984   5097800  ...   31.002930     0.000000\n","2021-05-11  572.118896   7139600  ...   98.857361     0.000000\n","2021-05-18  560.501526   4656400  ...  133.828491     0.000000\n","\n","[10 rows x 9 columns]\n"],"name":"stdout"}]}]}